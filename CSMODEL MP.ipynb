{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de097fbe",
   "metadata": {},
   "source": [
    "# CSMODEL Machine Project (Phase 1) ☕✨\n",
    "This Jupyter Notebook was made in compliance with the requirements set by the course Statistical Modelling and Simulation (CSMODEL). \n",
    "\n",
    "This machine project was prepared by the following students from section S16:\n",
    "- Filipino, Eunice Marble R.\n",
    "- Lazaro, Heisel Janine C.\n",
    "- Punsalan, Emmanuel Gerald G.\n",
    "- Wee, Justine Erika D.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb6eb79",
   "metadata": {},
   "source": [
    "# Import Libraries ⬇️\n",
    "\n",
    "The following libraries are imported to provide essential functionalities for data processing, analysis, and visualization throughout this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f500af11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scipy in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.14.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.23.5 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scipy) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from seaborn) (2.1.1)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from seaborn) (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: rapidfuzz in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.13.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openpyxl\n",
    "%pip install scipy\n",
    "%pip install seaborn\n",
    "%pip install rapidfuzz\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import ttest_ind\n",
    "from rapidfuzz import process, fuzz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e697f317",
   "metadata": {},
   "source": [
    "# Data Description ℹ️✨\n",
    "The [Coffee Bean Sales Dataset](https://www.kaggle.com/datasets/saadharoon27/coffee-bean-sales-raw-dataset/data) provides comprehensive insights into the coffee industry. It contains detailed information on coffee orders, customer profiles and product details. The dataset is divided into three worksheets, providing specific information about orders, customers and products. The orders worksheet reflects the coffee transactions made by customers. The customers worksheet contains specific details on the customers. Lastly, the products worksheet details each coffee product."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbf49a7",
   "metadata": {},
   "source": [
    "### How the data was collected\n",
    "\n",
    "The dataset was acquired from [Kaggle](https://www.kaggle.com) which houses datasets that may be from open sources, web scraping, or simulations. It is not outwardly stated how the coffee bean sales dataset was gathered, but it can be assumed that it was artificially generated for educational purposes due to the lack of details and metadata surrounding the orders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7a6890",
   "metadata": {},
   "source": [
    "### Potential Implications\n",
    "\n",
    "As the data was collected through unknown sources, there are potential implications on how information was recorded. The lack of standardization across dataset fields may lead to discrepancies, inconsistencies, or misleading conclusions during data analysis. Additionally, the lack of metadata challenges to determine the scope of the dataset—increasing the risk of sampling bias. It also imposes constraints in preprocessing since the dataset was provided in a pre-cleaned format; hence, further restricting the accuracy and relevance of the insights that will be generated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1981d246",
   "metadata": {},
   "source": [
    "### Dataset Overview (Structure and Attributes)\n",
    "\n",
    "The dataset is divided into three worksheets, which are the following:\n",
    "\n",
    "**Orders:** Consists of **1,000 observations** and **9 variables**, where each observation represents an order. The attributes of which include:\n",
    "\n",
    "| **Attribute** | **Description**                              |\n",
    "|---------------|----------------------------------------------|\n",
    "| **Order ID**  | A unique identifier for each order           |\n",
    "| **Order Date**| The date the order was placed                |\n",
    "| **Customer ID** | A reference to the customer who placed the order |\n",
    "| **Product ID** | A reference to the product ordered          |\n",
    "| **Quantity**  | The number of units ordered                  |\n",
    "\n",
    "**Customers:** Consists of **1,000 observations** and **9 variables**, where each observation represents a distinct customer. The attributes of which include:\n",
    "\n",
    "| **Attribute**     | **Description**                        |\n",
    "|-------------------|----------------------------------------|\n",
    "| **Customer ID**   | A unique identifier for each customer  |\n",
    "| **Customer Name** | The full name of the customer          |\n",
    "| **Email Address** | Contact email of the customer          |\n",
    "| **Phone Number**  | Customer’s phone contact               |\n",
    "| **Address Line 1**  | Primary street address of the customer |\n",
    "| **City**            | City of the customer’s address         |\n",
    "| **Country**         | Country of residence                   |\n",
    "| **Postcode**        | Postal/ZIP code of the customer’s address |\n",
    "| **Loyalty Card**    | Indicates whether the customer has a loyalty card (Yes/No) |\n",
    "\n",
    "**Products:** Consists of **48 observations** and **7 variables**, where each observation represents a unique coffee product. The attributes of which include:\n",
    "\n",
    "| **Attribute**     | **Description**                                     |\n",
    "|-------------------|--------------------------------------------------- |\n",
    "| **Product ID**    | A unique identifier for each product                |\n",
    "| **Coffee Type**   | The blend or type of coffee (e.g., Arabica, Robusta)|\n",
    "| **Roast Type**    | The level of roast (e.g., light, medium, dark)      |\n",
    "| **Size**          | Packaging size of the product                      |\n",
    "| **Unit Price**    | Retail price per unit                              |\n",
    "| **Price per 100g**| Standardized pricing for comparison                |\n",
    "| **Profit**        | Profitability of each product                      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fc7aa1",
   "metadata": {},
   "source": [
    "# Reading the Dataset 📝\n",
    "\n",
    "With all that in mind, let's load in the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eef40947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Excel file\n",
    "file_path = 'Coffee Bean Dataset.xlsx'\n",
    "\n",
    "# Loading each worksheet into a separate DataFrame\n",
    "orders = pd.read_excel(file_path, sheet_name = 'orders')\n",
    "customers = pd.read_excel(file_path, sheet_name = 'customers')\n",
    "products = pd.read_excel(file_path, sheet_name = 'products')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60be8cd",
   "metadata": {},
   "source": [
    "We should take a peek into the three worksheets to confirm our loading worked..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "caaaaf6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Email</th>\n",
       "      <th>Country</th>\n",
       "      <th>Coffee Type</th>\n",
       "      <th>Roast Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>Unit Price</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QEV-37451-860</td>\n",
       "      <td>2019-09-05</td>\n",
       "      <td>17670-51384-MA</td>\n",
       "      <td>R-M-1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QEV-37451-860</td>\n",
       "      <td>2019-09-05</td>\n",
       "      <td>17670-51384-MA</td>\n",
       "      <td>E-M-0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FAA-43335-268</td>\n",
       "      <td>2021-06-17</td>\n",
       "      <td>21125-22134-PX</td>\n",
       "      <td>A-L-1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KAC-83089-793</td>\n",
       "      <td>2021-07-15</td>\n",
       "      <td>23806-46781-OU</td>\n",
       "      <td>E-M-1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KAC-83089-793</td>\n",
       "      <td>2021-07-15</td>\n",
       "      <td>23806-46781-OU</td>\n",
       "      <td>R-L-2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Order ID Order Date     Customer ID Product ID  Quantity  \\\n",
       "0  QEV-37451-860 2019-09-05  17670-51384-MA      R-M-1         2   \n",
       "1  QEV-37451-860 2019-09-05  17670-51384-MA    E-M-0.5         5   \n",
       "2  FAA-43335-268 2021-06-17  21125-22134-PX      A-L-1         1   \n",
       "3  KAC-83089-793 2021-07-15  23806-46781-OU      E-M-1         2   \n",
       "4  KAC-83089-793 2021-07-15  23806-46781-OU    R-L-2.5         2   \n",
       "\n",
       "   Customer Name  Email  Country  Coffee Type  Roast Type  Size  Unit Price  \\\n",
       "0            NaN    NaN      NaN          NaN         NaN   NaN         NaN   \n",
       "1            NaN    NaN      NaN          NaN         NaN   NaN         NaN   \n",
       "2            NaN    NaN      NaN          NaN         NaN   NaN         NaN   \n",
       "3            NaN    NaN      NaN          NaN         NaN   NaN         NaN   \n",
       "4            NaN    NaN      NaN          NaN         NaN   NaN         NaN   \n",
       "\n",
       "   Sales  \n",
       "0    NaN  \n",
       "1    NaN  \n",
       "2    NaN  \n",
       "3    NaN  \n",
       "4    NaN  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "60b247b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Email</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Address Line 1</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Loyalty Card</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17670-51384-MA</td>\n",
       "      <td>Aloisia Allner</td>\n",
       "      <td>aallner0@lulu.com</td>\n",
       "      <td>+1 (862) 817-0124</td>\n",
       "      <td>57999 Pepper Wood Alley</td>\n",
       "      <td>Paterson</td>\n",
       "      <td>United States</td>\n",
       "      <td>7505</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73342-18763-UW</td>\n",
       "      <td>Piotr Bote</td>\n",
       "      <td>pbote1@yelp.com</td>\n",
       "      <td>+353 (913) 396-4653</td>\n",
       "      <td>2112 Ridgeway Hill</td>\n",
       "      <td>Crumlin</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>D6W</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21125-22134-PX</td>\n",
       "      <td>Jami Redholes</td>\n",
       "      <td>jredholes2@tmall.com</td>\n",
       "      <td>+1 (210) 986-6806</td>\n",
       "      <td>5214 Bartillon Park</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>United States</td>\n",
       "      <td>78205</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71253-00052-RN</td>\n",
       "      <td>Dene Azema</td>\n",
       "      <td>dazema3@facebook.com</td>\n",
       "      <td>+1 (217) 418-0714</td>\n",
       "      <td>27 Maywood Place</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>United States</td>\n",
       "      <td>62711</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23806-46781-OU</td>\n",
       "      <td>Christoffer O' Shea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+353 (698) 362-9201</td>\n",
       "      <td>38980 Manitowish Junction</td>\n",
       "      <td>Cill Airne</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>N41</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Customer ID        Customer Name                 Email  \\\n",
       "0  17670-51384-MA       Aloisia Allner     aallner0@lulu.com   \n",
       "1  73342-18763-UW           Piotr Bote       pbote1@yelp.com   \n",
       "2  21125-22134-PX        Jami Redholes  jredholes2@tmall.com   \n",
       "3  71253-00052-RN           Dene Azema  dazema3@facebook.com   \n",
       "4  23806-46781-OU  Christoffer O' Shea                   NaN   \n",
       "\n",
       "          Phone Number             Address Line 1         City        Country  \\\n",
       "0    +1 (862) 817-0124    57999 Pepper Wood Alley     Paterson  United States   \n",
       "1  +353 (913) 396-4653         2112 Ridgeway Hill      Crumlin        Ireland   \n",
       "2    +1 (210) 986-6806        5214 Bartillon Park  San Antonio  United States   \n",
       "3    +1 (217) 418-0714           27 Maywood Place  Springfield  United States   \n",
       "4  +353 (698) 362-9201  38980 Manitowish Junction   Cill Airne        Ireland   \n",
       "\n",
       "  Postcode Loyalty Card  \n",
       "0     7505          Yes  \n",
       "1      D6W           No  \n",
       "2    78205          Yes  \n",
       "3    62711          Yes  \n",
       "4      N41           No  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dbb36ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Coffee Type</th>\n",
       "      <th>Roast Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>Unit Price</th>\n",
       "      <th>Price per 100g</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-L-0.2</td>\n",
       "      <td>Ara</td>\n",
       "      <td>L</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.885</td>\n",
       "      <td>1.9425</td>\n",
       "      <td>0.34965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A-L-0.5</td>\n",
       "      <td>Ara</td>\n",
       "      <td>L</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.770</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>0.69930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A-L-1</td>\n",
       "      <td>Ara</td>\n",
       "      <td>L</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.950</td>\n",
       "      <td>1.2950</td>\n",
       "      <td>1.16550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-L-2.5</td>\n",
       "      <td>Ara</td>\n",
       "      <td>L</td>\n",
       "      <td>2.5</td>\n",
       "      <td>29.785</td>\n",
       "      <td>1.1914</td>\n",
       "      <td>2.68065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A-M-0.2</td>\n",
       "      <td>Ara</td>\n",
       "      <td>M</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.375</td>\n",
       "      <td>1.6875</td>\n",
       "      <td>0.30375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Product ID Coffee Type Roast Type  Size  Unit Price  Price per 100g   Profit\n",
       "0    A-L-0.2         Ara          L   0.2       3.885          1.9425  0.34965\n",
       "1    A-L-0.5         Ara          L   0.5       7.770          1.5540  0.69930\n",
       "2      A-L-1         Ara          L   1.0      12.950          1.2950  1.16550\n",
       "3    A-L-2.5         Ara          L   2.5      29.785          1.1914  2.68065\n",
       "4    A-M-0.2         Ara          M   0.2       3.375          1.6875  0.30375"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09a449d",
   "metadata": {},
   "source": [
    "Eureka! The Coffee Bean Dataset has loaded into our Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164d3aa6",
   "metadata": {},
   "source": [
    "But each worksheet only gives us partial information about the data... So, let's join the worksheets together to gain more insights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1cdd17b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging Orders with Customers on 'Customer ID'\n",
    "orders_customers = pd.merge(orders, customers, on = 'Customer ID', how = 'left')\n",
    "\n",
    "# Merging the result with Products on 'Product ID'\n",
    "coffee_df = pd.merge(orders_customers, products, on = 'Product ID', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e6dc56",
   "metadata": {},
   "source": [
    "Let's take another peek but now into the merged dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3bfae213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Customer Name_x</th>\n",
       "      <th>Email_x</th>\n",
       "      <th>Country_x</th>\n",
       "      <th>Coffee Type_x</th>\n",
       "      <th>Roast Type_x</th>\n",
       "      <th>...</th>\n",
       "      <th>City</th>\n",
       "      <th>Country_y</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Loyalty Card</th>\n",
       "      <th>Coffee Type_y</th>\n",
       "      <th>Roast Type_y</th>\n",
       "      <th>Size_y</th>\n",
       "      <th>Unit Price_y</th>\n",
       "      <th>Price per 100g</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QEV-37451-860</td>\n",
       "      <td>2019-09-05</td>\n",
       "      <td>17670-51384-MA</td>\n",
       "      <td>R-M-1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Paterson</td>\n",
       "      <td>United States</td>\n",
       "      <td>7505</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Rob</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.950</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>0.5970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QEV-37451-860</td>\n",
       "      <td>2019-09-05</td>\n",
       "      <td>17670-51384-MA</td>\n",
       "      <td>E-M-0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Paterson</td>\n",
       "      <td>United States</td>\n",
       "      <td>7505</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Exc</td>\n",
       "      <td>M</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.250</td>\n",
       "      <td>1.6500</td>\n",
       "      <td>0.9075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FAA-43335-268</td>\n",
       "      <td>2021-06-17</td>\n",
       "      <td>21125-22134-PX</td>\n",
       "      <td>A-L-1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>United States</td>\n",
       "      <td>78205</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Ara</td>\n",
       "      <td>L</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.950</td>\n",
       "      <td>1.2950</td>\n",
       "      <td>1.1655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KAC-83089-793</td>\n",
       "      <td>2021-07-15</td>\n",
       "      <td>23806-46781-OU</td>\n",
       "      <td>E-M-1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Cill Airne</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>N41</td>\n",
       "      <td>No</td>\n",
       "      <td>Exc</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.750</td>\n",
       "      <td>1.3750</td>\n",
       "      <td>1.5125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KAC-83089-793</td>\n",
       "      <td>2021-07-15</td>\n",
       "      <td>23806-46781-OU</td>\n",
       "      <td>R-L-2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Cill Airne</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>N41</td>\n",
       "      <td>No</td>\n",
       "      <td>Rob</td>\n",
       "      <td>L</td>\n",
       "      <td>2.5</td>\n",
       "      <td>27.485</td>\n",
       "      <td>1.0994</td>\n",
       "      <td>1.6491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Order ID Order Date     Customer ID Product ID  Quantity  \\\n",
       "0  QEV-37451-860 2019-09-05  17670-51384-MA      R-M-1         2   \n",
       "1  QEV-37451-860 2019-09-05  17670-51384-MA    E-M-0.5         5   \n",
       "2  FAA-43335-268 2021-06-17  21125-22134-PX      A-L-1         1   \n",
       "3  KAC-83089-793 2021-07-15  23806-46781-OU      E-M-1         2   \n",
       "4  KAC-83089-793 2021-07-15  23806-46781-OU    R-L-2.5         2   \n",
       "\n",
       "   Customer Name_x  Email_x  Country_x  Coffee Type_x  Roast Type_x  ...  \\\n",
       "0              NaN      NaN        NaN            NaN           NaN  ...   \n",
       "1              NaN      NaN        NaN            NaN           NaN  ...   \n",
       "2              NaN      NaN        NaN            NaN           NaN  ...   \n",
       "3              NaN      NaN        NaN            NaN           NaN  ...   \n",
       "4              NaN      NaN        NaN            NaN           NaN  ...   \n",
       "\n",
       "          City      Country_y  Postcode Loyalty Card Coffee Type_y  \\\n",
       "0     Paterson  United States      7505          Yes           Rob   \n",
       "1     Paterson  United States      7505          Yes           Exc   \n",
       "2  San Antonio  United States     78205          Yes           Ara   \n",
       "3   Cill Airne        Ireland       N41           No           Exc   \n",
       "4   Cill Airne        Ireland       N41           No           Rob   \n",
       "\n",
       "  Roast Type_y Size_y Unit Price_y Price per 100g  Profit  \n",
       "0            M    1.0        9.950         0.9950  0.5970  \n",
       "1            M    0.5        8.250         1.6500  0.9075  \n",
       "2            L    1.0       12.950         1.2950  1.1655  \n",
       "3            M    1.0       13.750         1.3750  1.5125  \n",
       "4            L    2.5       27.485         1.0994  1.6491  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coffee_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33faddc",
   "metadata": {},
   "source": [
    "We're all set! We can now proceed to cleaning the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bec60b5",
   "metadata": {},
   "source": [
    "# Data Cleaning 🧹✨ \n",
    "\n",
    "Before performing analysis, it is essential to clean the dataset so we ensure accuracy and reliability of results. We'll be handling variables and values with **multiple representations**, **incorrect datatypes**, **missing data**, **duplicate data**, **inconsistent formatting**, and **outliers**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf7674e",
   "metadata": {},
   "source": [
    "But let's look at the dataset and its variables again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "49830000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 27 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   Order ID         1000 non-null   object        \n",
      " 1   Order Date       1000 non-null   datetime64[ns]\n",
      " 2   Customer ID      1000 non-null   object        \n",
      " 3   Product ID       1000 non-null   object        \n",
      " 4   Quantity         1000 non-null   int64         \n",
      " 5   Customer Name_x  0 non-null      float64       \n",
      " 6   Email_x          0 non-null      float64       \n",
      " 7   Country_x        0 non-null      float64       \n",
      " 8   Coffee Type_x    0 non-null      float64       \n",
      " 9   Roast Type_x     0 non-null      float64       \n",
      " 10  Size_x           0 non-null      float64       \n",
      " 11  Unit Price_x     0 non-null      float64       \n",
      " 12  Sales            0 non-null      float64       \n",
      " 13  Customer Name_y  1000 non-null   object        \n",
      " 14  Email_y          794 non-null    object        \n",
      " 15  Phone Number     865 non-null    object        \n",
      " 16  Address Line 1   1000 non-null   object        \n",
      " 17  City             1000 non-null   object        \n",
      " 18  Country_y        1000 non-null   object        \n",
      " 19  Postcode         1000 non-null   object        \n",
      " 20  Loyalty Card     1000 non-null   object        \n",
      " 21  Coffee Type_y    1000 non-null   object        \n",
      " 22  Roast Type_y     1000 non-null   object        \n",
      " 23  Size_y           1000 non-null   float64       \n",
      " 24  Unit Price_y     1000 non-null   float64       \n",
      " 25  Price per 100g   1000 non-null   float64       \n",
      " 26  Profit           1000 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(12), int64(1), object(13)\n",
      "memory usage: 211.1+ KB\n"
     ]
    }
   ],
   "source": [
    "coffee_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef19247f",
   "metadata": {},
   "source": [
    "There's a lot of variables we don't need. We can drop those. Goodbye!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "29c301cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 19 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Order ID        1000 non-null   object        \n",
      " 1   Order Date      1000 non-null   datetime64[ns]\n",
      " 2   Customer ID     1000 non-null   object        \n",
      " 3   Product ID      1000 non-null   object        \n",
      " 4   Quantity        1000 non-null   int64         \n",
      " 5   Customer Name   1000 non-null   object        \n",
      " 6   Email           794 non-null    object        \n",
      " 7   Phone Number    865 non-null    object        \n",
      " 8   Address Line 1  1000 non-null   object        \n",
      " 9   City            1000 non-null   object        \n",
      " 10  Country         1000 non-null   object        \n",
      " 11  Postcode        1000 non-null   object        \n",
      " 12  Loyalty Card    1000 non-null   object        \n",
      " 13  Coffee Type     1000 non-null   object        \n",
      " 14  Roast Type      1000 non-null   object        \n",
      " 15  Size            1000 non-null   float64       \n",
      " 16  Unit Price      1000 non-null   float64       \n",
      " 17  Price per 100g  1000 non-null   float64       \n",
      " 18  Profit          1000 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(4), int64(1), object(13)\n",
      "memory usage: 148.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Dropping the useless columns\n",
    "columns_to_drop = [\n",
    "    'Customer Name_x', \n",
    "    'Email_x', \n",
    "    'Country_x', \n",
    "    'Coffee Type_x', \n",
    "    'Roast Type_x', \n",
    "    'Size_x', \n",
    "    'Unit Price_x', \n",
    "    'Sales']\n",
    "clean_coffee_df = coffee_df.drop(columns = columns_to_drop)\n",
    "\n",
    "# Renaming remaining columns for clarity\n",
    "clean_coffee_df = clean_coffee_df.rename(columns = {\n",
    "    'Customer Name_y': 'Customer Name',\n",
    "    'Email_y': 'Email',\n",
    "    'Country_y': 'Country',\n",
    "    'Coffee Type_y': 'Coffee Type',\n",
    "    'Roast Type_y': 'Roast Type',\n",
    "    'Size_y': 'Size',\n",
    "    'Unit Price_y': 'Unit Price'\n",
    "})\n",
    "\n",
    "clean_coffee_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67347ea",
   "metadata": {},
   "source": [
    "Looking good so far! We can now proceed to cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81705efa",
   "metadata": {},
   "source": [
    "### Incorrect Datatypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a5a119",
   "metadata": {},
   "source": [
    "Incorrect Datatypes happen when the type of data stored in a column doesn’t match what it should be for correct analysis or operations. \n",
    "\n",
    "Strings shouldn't be stored as Floats! Dates shouldn't be stored as plain text... We might run into problems for computing.\n",
    "\n",
    "So, let's correct these incorrects!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6d17ac",
   "metadata": {},
   "source": [
    "| **Attribute**       | **Data Type**    |\n",
    "|---------------------|------------------|\n",
    "| **Order ID**        | object (string)  |\n",
    "| **Order Date**      | datetime64[ns]   |\n",
    "| **Customer ID**     | object (string)  |\n",
    "| **Product ID**      | object (string)  |\n",
    "| **Quantity**        | int64            |\n",
    "| **Customer Name**   | object (string)  |\n",
    "| **Email**           | object (string)  |\n",
    "| **Phone Number**    | object (string)  |\n",
    "| **Address Line 1**  | object (string)  |\n",
    "| **City**            | object (string)  |\n",
    "| **Country**         | object (string)  |\n",
    "| **Postcode**        | object (string)  |\n",
    "| **Loyalty Card**    | object (string)  |\n",
    "| **Coffee Type**     | object (string)  |\n",
    "| **Roast Type**      | object (string)  |\n",
    "| **Size**            | float64          |\n",
    "| **Unit Price**      | float64          |\n",
    "| **Price per 100g**  | float64          |\n",
    "| **Profit**          | float64          |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771f2e81",
   "metadata": {},
   "source": [
    "Unique identifiers like the Order ID, Customer ID, and Product ID are stored as objects, specifically strings. No problems here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "61eb7d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(clean_coffee_df['Order ID'].iloc[0]))\n",
    "print(type(clean_coffee_df['Customer ID'].iloc[0]))\n",
    "print(type(clean_coffee_df['Product ID'].iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865bf661",
   "metadata": {},
   "source": [
    "Order Dates are stored as objects, specifically a datetime date. All good on this end!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5c28337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_coffee_df['Order Date'] = pd.to_datetime(clean_coffee_df['Order Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "48b60049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n"
     ]
    }
   ],
   "source": [
    "print(type(clean_coffee_df['Order Date'].iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34ab19b",
   "metadata": {},
   "source": [
    "On that note, textual information like the Customer Name, Email, Address Line 1, City, Country, Phone Numbers, and Postcodes should be strings also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a397a0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(clean_coffee_df['Customer Name'].iloc[0]))\n",
    "print(type(clean_coffee_df['Email'].iloc[0]))\n",
    "print(type(clean_coffee_df['Address Line 1'].iloc[0]))\n",
    "print(type(clean_coffee_df['City'].iloc[0]))\n",
    "print(type(clean_coffee_df['Country'].iloc[0]))\n",
    "print(type(clean_coffee_df['Phone Number'].iloc[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9fdfdf",
   "metadata": {},
   "source": [
    "Oh no! All the other variables are correct but Postcodes are represented as ints, so let's fix that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "daeb5d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_coffee_df['Postcode'] = clean_coffee_df['Postcode'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f02c50ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(clean_coffee_df['Postcode'].iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bf2c14",
   "metadata": {},
   "source": [
    "The Loyalty Card variable is filled with \"Yes\" and \"No\", but it would be much better to analyze boolean values. Would that be true or false?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9548bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_coffee_df['Loyalty Card'] = clean_coffee_df['Loyalty Card'].map({'Yes': True, 'No': False}).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d4830b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.bool'>\n"
     ]
    }
   ],
   "source": [
    "print(type(clean_coffee_df['Loyalty Card'].iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b0cb83",
   "metadata": {},
   "source": [
    "Numerical information like Unit Price, Price per 100g, Profit, Size, and Quantity are already floats and int respectively. No need for corrections!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2eb97cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "print(type(clean_coffee_df['Unit Price'].iloc[0]))\n",
    "print(type(clean_coffee_df['Price per 100g'].iloc[0]))\n",
    "print(type(clean_coffee_df['Profit'].iloc[0]))\n",
    "print(type(clean_coffee_df['Size'].iloc[0]))\n",
    "print(type(clean_coffee_df['Quantity'].iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3358fa",
   "metadata": {},
   "source": [
    "Information that uses the same set of values can be identified into categories. For the Coffee Type, Roast Type, and Size, we can convert them to the category datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7607115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_coffee_df['Coffee Type'] = clean_coffee_df['Coffee Type'].astype('category')\n",
    "clean_coffee_df['Roast Type'] = clean_coffee_df['Roast Type'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f024db65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "category\n"
     ]
    }
   ],
   "source": [
    "print(clean_coffee_df['Coffee Type'].dtype)\n",
    "print(clean_coffee_df['Roast Type'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927ae8ac",
   "metadata": {},
   "source": [
    "We're all set, the datatypes now fit the variables! Good job!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b7e0e3",
   "metadata": {},
   "source": [
    "### Multiple Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f385e0d2",
   "metadata": {},
   "source": [
    "Some observations may have the same value but presented differently. That's what we call \"Multiple Representations\"\n",
    "\n",
    "Just as an example, there are observations in Country \"U.S.A\", \"United States of America\", and \"USA\". That's too many! We have make America consistent again!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171de211",
   "metadata": {},
   "source": [
    "We can start with the categorical variables since they're expected to be consistent all throughout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "00f4c507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rob', 'Exc', 'Ara', 'Lib']\n",
      "Categories (4, object): ['Ara', 'Exc', 'Lib', 'Rob']\n",
      "['M', 'L', 'D']\n",
      "Categories (3, object): ['D', 'L', 'M']\n"
     ]
    }
   ],
   "source": [
    "print(clean_coffee_df['Coffee Type'].unique())\n",
    "print(clean_coffee_df['Roast Type'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e067c9",
   "metadata": {},
   "source": [
    "There are 4 distinct objects for Coffee Type and there are no duplicates among the values found, same goes with the Roast Type. So, we can conclude that there are no multiple representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3511d6",
   "metadata": {},
   "source": [
    "Same logic goes for the Country variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e940dd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['United States' 'Ireland' 'United Kingdom']\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(clean_coffee_df['Country'].unique())\n",
    "print(clean_coffee_df['Country'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886a0d81",
   "metadata": {},
   "source": [
    "Now we check for the City variable, but there are too many of them to look manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3bfd14c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375\n"
     ]
    }
   ],
   "source": [
    "print(clean_coffee_df['City'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be846c0a",
   "metadata": {},
   "source": [
    "We can use fuzzy matching to check if any cities are spelled the same but formatted differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "39ec864c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scranton ↔ [('canton', 85.71428571428572)]\n",
      "nashville ↔ [('asheville', 88.88888888888889)]\n",
      "reston ↔ [('preston', 92.3076923076923)]\n",
      "carlton ↔ [('charlton', 93.33333333333333)]\n",
      "charlton ↔ [('carlton', 93.33333333333333), ('charleston', 88.88888888888889), ('halton', 85.71428571428572)]\n",
      "sallins ↔ [('salinas', 85.71428571428572)]\n",
      "canton ↔ [('scranton', 85.71428571428572)]\n",
      "charleston ↔ [('charlton', 88.88888888888889)]\n",
      "halton ↔ [('charlton', 85.71428571428572)]\n",
      "asheville ↔ [('nashville', 88.88888888888889)]\n",
      "salinas ↔ [('sallins', 85.71428571428572)]\n",
      "seaton ↔ [('eaton', 90.9090909090909)]\n",
      "eaton ↔ [('seaton', 90.9090909090909)]\n",
      "preston ↔ [('reston', 92.3076923076923)]\n"
     ]
    }
   ],
   "source": [
    "# Settingn list of cities to lowercase\n",
    "cities = list(set([c.lower() for c in clean_coffee_df['City'].unique()]))\n",
    "\n",
    "# Setting similarity threshold\n",
    "THRESHOLD = 85  \n",
    "\n",
    "# Checking for potential duplicates\n",
    "for city in cities:\n",
    "    matches = process.extract(city, cities, scorer=fuzz.ratio, limit=None)\n",
    "    similar = [(match, score) for match, score, _ in matches if match != city and score >= THRESHOLD]\n",
    "    if similar:\n",
    "        print(f\"{city} ↔ {similar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777979ae",
   "metadata": {},
   "source": [
    "It looks like "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e84d2f",
   "metadata": {},
   "source": [
    "### Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b089a1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Order ID          0\n",
       "Order Date        0\n",
       "Customer ID       0\n",
       "Product ID        0\n",
       "Quantity          0\n",
       "Customer Name     0\n",
       "Email             0\n",
       "Phone Number      0\n",
       "Address Line 1    0\n",
       "City              0\n",
       "Country           0\n",
       "Postcode          0\n",
       "Loyalty Card      0\n",
       "Coffee Type       0\n",
       "Roast Type        0\n",
       "Size              0\n",
       "Unit Price        0\n",
       "Price per 100g    0\n",
       "Profit            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_coffee_df = clean_coffee_df[\n",
    "    (clean_coffee_df['Loyalty Card'].isin(['True', 'False'])) &\n",
    "    (clean_coffee_df['Quantity'].notnull())\n",
    "]\n",
    "clean_coffee_df.head()\n",
    "\n",
    "clean_coffee_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c3d28107",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_coffee_df['Email'] = clean_coffee_df['Email'].fillna('NaN')\n",
    "clean_coffee_df['Phone Number'] = clean_coffee_df['Phone Number'].fillna('NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "299220c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Order ID          0\n",
       "Order Date        0\n",
       "Customer ID       0\n",
       "Product ID        0\n",
       "Quantity          0\n",
       "Customer Name     0\n",
       "Email             0\n",
       "Phone Number      0\n",
       "Address Line 1    0\n",
       "City              0\n",
       "Country           0\n",
       "Postcode          0\n",
       "Loyalty Card      0\n",
       "Coffee Type       0\n",
       "Roast Type        0\n",
       "Size              0\n",
       "Unit Price        0\n",
       "Price per 100g    0\n",
       "Profit            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_coffee_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee77ca7",
   "metadata": {},
   "source": [
    "### Duplicate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6c032239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Email</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Address Line 1</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Loyalty Card</th>\n",
       "      <th>Coffee Type</th>\n",
       "      <th>Roast Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>Unit Price</th>\n",
       "      <th>Price per 100g</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Order ID, Order Date, Customer ID, Product ID, Quantity, Customer Name, Email, Phone Number, Address Line 1, City, Country, Postcode, Loyalty Card, Coffee Type, Roast Type, Size, Unit Price, Price per 100g, Profit]\n",
       "Index: []"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_coffee_df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350e6aa6",
   "metadata": {},
   "source": [
    "### Inconsistent Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0887ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b63a340",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db4efee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1b4b17e",
   "metadata": {},
   "source": [
    "Our dataset is now squeaky clean! We can now proceed with analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d7da8d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Data columns (total 19 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Order ID        0 non-null      object        \n",
      " 1   Order Date      0 non-null      datetime64[ns]\n",
      " 2   Customer ID     0 non-null      object        \n",
      " 3   Product ID      0 non-null      object        \n",
      " 4   Quantity        0 non-null      int64         \n",
      " 5   Customer Name   0 non-null      object        \n",
      " 6   Email           0 non-null      object        \n",
      " 7   Phone Number    0 non-null      object        \n",
      " 8   Address Line 1  0 non-null      object        \n",
      " 9   City            0 non-null      object        \n",
      " 10  Country         0 non-null      object        \n",
      " 11  Postcode        0 non-null      object        \n",
      " 12  Loyalty Card    0 non-null      bool          \n",
      " 13  Coffee Type     0 non-null      category      \n",
      " 14  Roast Type      0 non-null      category      \n",
      " 15  Size            0 non-null      float64       \n",
      " 16  Unit Price      0 non-null      float64       \n",
      " 17  Price per 100g  0 non-null      float64       \n",
      " 18  Profit          0 non-null      float64       \n",
      "dtypes: bool(1), category(2), datetime64[ns](1), float64(4), int64(1), object(10)\n",
      "memory usage: 336.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "clean_coffee_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2439fc6",
   "metadata": {},
   "source": [
    "# Target Research Question 🔬✨\n",
    "\n",
    "#### _`\"How can we optimize business strategies by understanding the factors that affect sales?\"`_\n",
    "\n",
    "In order to provide scope, purpose, and clarity, the above question will serve as the main foundation of data analysis upon the Coffee Bean Sale Dataset. It will guide in identifying patterns, relationships, and key insights that can inform business decision-making to hopefully draw insights on the coffee bean industry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fba408",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis 🔍✨\n",
    "\n",
    "Now that the dataset has been cleaned, we can start exploring it to better understand its structure, contents, and patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d42d84",
   "metadata": {},
   "source": [
    "People tend to prefer certain flavors of coffee depending on the season like how Pumpkin Spice Lattes take over Autumn. By knowing which coffee beans and roasts are most profitable, we can make smarter decisions about stocks and promotions. This begs the question...\n",
    "\n",
    "### _`\"Which coffee bean and roast type is the most profitable per season?\"`_ ⛅📈✨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beee6c2",
   "metadata": {},
   "source": [
    "To answer this question, the variables of interest are:\n",
    "- **`Order Date`**: the date a order was placed\n",
    "- **`Coffee Type`**: the blend or type of coffee (e.g., Arabica, Robusta, Liberica, Excelsa)\n",
    "- **`Roast Type`**: the level of roast (e.g., light, medium, dark)\n",
    "- **`Profit`**: the amount of profit from a sale\n",
    "- **`Quantity`**: the number of units ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6b098f",
   "metadata": {},
   "source": [
    "#### Seasons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd04fcf6",
   "metadata": {},
   "source": [
    "Since the customers from the dataset are mostly from the the United States of America, we will be using the seasons from that country. The seasons are specifically **winter**, **spring**, **summer** and **fall** and they will be derived from the `Order Date`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4fdca73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Order Date, Season]\n",
       "Index: []"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assigning seasons to a month\n",
    "def get_season(date):\n",
    "    if pd.isna(date):\n",
    "        return 'Unknown'\n",
    "    month = date.month\n",
    "    if month in [3, 4, 5]: return 'Spring'\n",
    "    elif month in [6, 7, 8]: return 'Summer'\n",
    "    elif month in [9, 10, 11]: return 'Fall'\n",
    "    else: return 'Winter'\n",
    "\n",
    "clean_coffee_df['Season'] = clean_coffee_df['Order Date'].apply(get_season) # Applying to DataFrame\n",
    "clean_coffee_df[['Order Date', 'Season']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b58fde4",
   "metadata": {},
   "source": [
    "#### **Total Quantity Sold For Each Coffee Type per Season**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3833a41",
   "metadata": {},
   "source": [
    "In order to understand the seasonal demands per coffee type (e.g., Arabica, Robusta), we will compute the total quantity sold for each coffee type per season. This will help us identify the coffee type that is most preferred during each season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "929c2b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Quantity Sold For Each Coffee Type per Season:\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [Season, Coffee Type, Quantity]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\punsa\\AppData\\Local\\Temp\\ipykernel_9976\\2783062445.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  coffee_total_quantity = clean_coffee_df.groupby(['Season', 'Coffee Type'])['Quantity'].sum().reset_index()\n"
     ]
    }
   ],
   "source": [
    "# Grouping by season and coffee type and summing up the quantity\n",
    "coffee_total_quantity = clean_coffee_df.groupby(['Season', 'Coffee Type'])['Quantity'].sum().reset_index()\n",
    "\n",
    "# Sorting the seasons in ascending order and quantity in descending order\n",
    "coffee_total_quantity = coffee_total_quantity.sort_values(['Season', 'Quantity'], ascending=[True, False])\n",
    "\n",
    "print(\"Total Quantity Sold For Each Coffee Type per Season:\\n\")\n",
    "print(coffee_total_quantity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff2fb81",
   "metadata": {},
   "source": [
    "During the **Fall** and **Summer**, the most sold coffee type for both seasons is **Arabica**, with a quantity of **233** and **247** units sold, respectively. During the **Spring**, the most sold coffee type is **Robusta**, with a quantity of **254** units sold. Lastly, during the **Winter**, the most sold coffee type is **Liberica**, with a quantity of **247** units sold. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8305e6",
   "metadata": {},
   "source": [
    "#### **Total Quantity Sold For Each Roast Type per Season**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8233035",
   "metadata": {},
   "source": [
    "In order to understand the seasonal demands per roast type (e.g., light, medium, dark), we will compute the total quantity sold for each roast type per season. This will help us identify the roast type that is most preferred during each season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0da863c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Roast Type_y'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[94]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Grouping by season and roast type and summing up the quantity\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m roast_total_quantity = \u001b[43mclean_coffee_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSeason\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mRoast Type_y\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mQuantity\u001b[39m\u001b[33m'\u001b[39m].sum().reset_index()\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Sorting the seasons in ascending order and quantity in descending order\u001b[39;00m\n\u001b[32m      5\u001b[39m roast_total_quantity = roast_total_quantity.sort_values([\u001b[33m'\u001b[39m\u001b[33mSeason\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mQuantity\u001b[39m\u001b[33m'\u001b[39m], ascending=[\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\punsa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:9183\u001b[39m, in \u001b[36mDataFrame.groupby\u001b[39m\u001b[34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   9180\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   9181\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to supply one of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mby\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m9183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   9184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   9185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9186\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9187\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9189\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9190\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9191\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9192\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9193\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\punsa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1329\u001b[39m, in \u001b[36mGroupBy.__init__\u001b[39m\u001b[34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   1326\u001b[39m \u001b[38;5;28mself\u001b[39m.dropna = dropna\n\u001b[32m   1328\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1329\u001b[39m     grouper, exclusions, obj = \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1337\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n\u001b[32m   1340\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping._passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper.groupings):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\punsa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:1043\u001b[39m, in \u001b[36mget_grouper\u001b[39m\u001b[34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[39m\n\u001b[32m   1041\u001b[39m         in_axis, level, gpr = \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[32m   1044\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr.key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1045\u001b[39m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[32m   1046\u001b[39m     exclusions.add(gpr.key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Roast Type_y'"
     ]
    }
   ],
   "source": [
    "# Grouping by season and roast type and summing up the quantity\n",
    "roast_total_quantity = clean_coffee_df.groupby(['Season', 'Roast Type_y'])['Quantity'].sum().reset_index()\n",
    "\n",
    "# Sorting the seasons in ascending order and quantity in descending order\n",
    "roast_total_quantity = roast_total_quantity.sort_values(['Season', 'Quantity'], ascending=[True, False])\n",
    "\n",
    "print(\"Total Quantity Sold For Each Roast Type per Season:\\n\")\n",
    "print(roast_total_quantity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fff5c01",
   "metadata": {},
   "source": [
    "During the **Winter** and **Summer**, the most sold roast type for both seasons is **dark**, with a quantity of **316** and **311** units sold, respectively. During the **Fall**, the most sold roast type is **medium**, with a quantity of **309** units sold. Lastly, during the **Spring**, the most sold roast type is **light**, with a quantity of **364** units sold. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92255def",
   "metadata": {},
   "source": [
    "#### **Top Quantity Sold For Each Coffee and Roast Type Combination per Season**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2394b3",
   "metadata": {},
   "source": [
    "In order to be a step closer to identifying what coffee and roast type is the most profitable per season, we will compute for the most quantity sold coffee and roast type combination per season. This will help us compare which coffee and roast type combination is the most sold and the most profitable during each season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dfe93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by season, coffee type, and roast type and summing up the quantity\n",
    "combination_quantity = clean_coffee_df.groupby(['Season', 'Coffee Type', 'Roast Type'])['Quantity'].sum().reset_index()\n",
    "\n",
    "# Sorting and retrieving the top selling combination per season\n",
    "top_combination_quantity = combination_quantity.sort_values(['Season', 'Quantity'], ascending=[True, False]) \\\n",
    "                                   .groupby('Season').first().reset_index()\n",
    "\n",
    "print(\"Top Quantity Sold for Each Coffee and Roast Type per Season:\\n\")\n",
    "print(top_combination_quantity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1270e7",
   "metadata": {},
   "source": [
    "During both the **Fall** and **Winter**, the most sold combination is **Arabica Medium Roast**, both having a quantity of **98** units sold. During the **Spring**, the most sold combination is **Excelsa Light Roast**, with a quantity of **106** units sold. During the **Summer**, the most sold combination is **Robusta Dark Roast**, with a quantity of **110** units sold.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757aca8c",
   "metadata": {},
   "source": [
    "#### **Most Profitable Coffee and Roast Type per Season**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912e1657",
   "metadata": {},
   "source": [
    "In order to answer our main EDA question of determining which coffee bean and roast type is the most profitable per season is, we will get the total profit of each season, coffee and roast type group and retreieve the combinations with the highest total profit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592de241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the total profit by multiplying quantity and profit\n",
    "clean_coffee_df['Total Profit'] = clean_coffee_df['Quantity'] * clean_coffee_df['Profit']\n",
    "\n",
    "# Grouping by season, coffee type, and roast type and then summing up the total profit for each group\n",
    "combination_season_profit = clean_coffee_df.groupby(['Season', 'Coffee Type', 'Roast Type'])['Total Profit'].sum().reset_index()\n",
    "\n",
    "# the coffee and roast type combination with the highest total profit appears first\n",
    "top_combination_per_season = combination_season_profit.sort_values(['Season', 'Total Profit'], ascending=[True, False]).groupby('Season').first().reset_index()\n",
    "\n",
    "print(top_combination_per_season)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfbc1ee",
   "metadata": {},
   "source": [
    "The most profitable coffee and roast type combination during the **Fall** is **Liberica Dark Roast** in contrast to **Arabica Medium Roast** having the most quantity sold. The most profitable combination during **Spring** is **Liberica Light Roast** in contrast to **Excelsa Light Roast** having the most quantity sold. The most profitable combination during **Summer** is **Excelsa Medium Roast** in contrast to **Robusta Dark Roast** having the most quantity sold. Lastly, the most profitable combination during **Winter** is **Liberica Dark Roast** in contrast to **Arabica Medium Roast** having the most quantity sold.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0c605a",
   "metadata": {},
   "source": [
    "#### **Which season has the highest overall coffee sales profit?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31e7c2b",
   "metadata": {},
   "source": [
    "Identifying the season with the highest overall coffee sales profit will help us understand which season generates the most coffee sales. By analyzing seasonal trends, businesses can better anticipate coffee demand and maximize profitability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deac87e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by season and summing up total profit\n",
    "season_profit = clean_coffee_df.groupby('Season')['Total Profit'].sum()\n",
    "\n",
    "# Sorting the profit per season in descending order\n",
    "season_profit_sorted = season_profit.sort_values(ascending=False)\n",
    "\n",
    "print(\"Total Profit per Season:\")\n",
    "for season, profit in season_profit_sorted.items():\n",
    "    print(f\"{season}: ${'{:.2f}'.format(profit)}\")\n",
    "\n",
    "top_season = season_profit_sorted.idxmax()\n",
    "\n",
    "print(f\"\\nSeason with the highest profit: {top_season}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1dac29",
   "metadata": {},
   "source": [
    "#### **Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f9f25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating data for plotting\n",
    "profit_per_type = clean_coffee_df.groupby(['Season', 'Coffee Type_y'])['Total Profit'].sum().reset_index()\n",
    "\n",
    "pivot_df = profit_per_type.pivot(index='Season', columns='Coffee Type_y', values='Total Profit')\n",
    "\n",
    "pivot_df.plot(kind='line', marker='o', figsize=(10,6))\n",
    "plt.title(\"Seasonal Profit Trends by Coffee Type\")\n",
    "plt.xlabel(\"Season\")\n",
    "plt.ylabel(\"Total Profit ($)\")\n",
    "plt.grid(True)\n",
    "plt.legend(title=\"Coffee Type\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be88075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by Season, Coffee Type, and Roast Type to get total profit\n",
    "profit_per_combo = clean_coffee_df.groupby(['Season', 'Coffee Type_y', 'Roast Type_y'])['Total Profit'].sum().reset_index()\n",
    "\n",
    "# Create a new column to combine Coffee Type and Roast Type for clearer labels\n",
    "profit_per_combo['CoffeeRoast'] = profit_per_combo['Coffee Type_y'] + ' - ' + profit_per_combo['Roast Type_y']\n",
    "\n",
    "# Pivot for plotting\n",
    "pivot_df = profit_per_combo.pivot(index='Season', columns='CoffeeRoast', values='Total Profit')\n",
    "\n",
    "# Plotting\n",
    "pivot_df.plot(kind='line', marker='o', figsize=(12, 6))\n",
    "plt.title(\"Seasonal Profit Trends by Coffee and Roast Type\")\n",
    "plt.xlabel(\"Season\")\n",
    "plt.ylabel(\"Total Profit ($)\")\n",
    "plt.grid(True)\n",
    "plt.legend(title=\"Coffee - Roast Type\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e6d572",
   "metadata": {},
   "source": [
    "// INSERT TRANSITIONAL STATEMENT HERE\n",
    "\n",
    "### _`\"How does loyalty card ownership influence customer purchasing behavior?\"`_ 🧑💳✨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9e2259",
   "metadata": {},
   "source": [
    "This analysis explores whether loyalty card ownership has an influence on customer purchasing behavior.  Specifically, we investigate whether there is a statistically significant difference in the number of coffee bean units ordered by customers who have a loyalty card compared to those who do not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b6a394",
   "metadata": {},
   "source": [
    "To do this, we focus on two variables:\n",
    "\n",
    "- **Loyalty Card**: From the `customers` dataset, indicating whether a customer has a loyalty card (True or False).\n",
    "- **Quantity**: From the `orders` dataset, representing how many units of coffee beans were ordered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b30c7f",
   "metadata": {},
   "source": [
    "We then divide the dataset into two groups based on loyalty card status:\n",
    "- `owners`: Customers who have a loyalty card (Loyalty Card == 'True')\n",
    "- `non_owners`: Customers who do not have a loyalty card (Loyalty Card == 'False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe4b07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "owners = clean_coffee_df[clean_coffee_df['Loyalty Card'] == 'True']['Quantity']\n",
    "non_owners = clean_coffee_df[clean_coffee_df['Loyalty Card'] == 'False']['Quantity']\n",
    "\n",
    "ownership_table = pd.DataFrame({\n",
    "    'Loyalty Card Owners': owners.reset_index(drop=True),\n",
    "    'Non-Owners': non_owners.reset_index(drop=True)\n",
    "})\n",
    "ownership_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c665d4",
   "metadata": {},
   "source": [
    "To assess the relationship, we use an **Independent Samples T-test**, which allows us to compare the means of two groups and determine whether any observed difference is statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815f09ca",
   "metadata": {},
   "source": [
    "Before conducting the test, we define our hypotheses:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cb4f68",
   "metadata": {},
   "source": [
    "**Null Hypothesis (H₀)**: Loyalty card ownership does not influence purchasing behavior.\n",
    "\n",
    "**Alternative Hypothesis (Hₐ)**: Loyalty card ownership does influence purchasing behavior.\n",
    "\n",
    "We will use an independent samples T-test to determine if the difference in purchasing behavior between loyalty card owners and non-owners is statistically significant based on the T-statistic and p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5f638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stat, p_value = ttest_ind(owners, non_owners, equal_var=False)\n",
    "\n",
    "print(f\"Owners Mean Quantity (True): {owners.mean():.2f}\")\n",
    "print(f\"Non-Owners Mean Quantity (False): {non_owners.mean():.2f}\")\n",
    "print(f\"T-statistic: {t_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5049887",
   "metadata": {},
   "source": [
    "The average quantity ordered by **loyalty card owners** is **3.48**, while **non-owners** order an average of **3.62**.\n",
    "\n",
    "The **T-statistic** is **-1.3518**, and the **p-value** is **0.1768**, which is greater than **0.05**. This means the result is **not statistically significant**. \n",
    "\n",
    "Therefore, we **fail to reject the null hypothesis**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52cf362",
   "metadata": {},
   "source": [
    "The dot plot below further illustrates this relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227472b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 6))\n",
    "sns.stripplot(\n",
    "    data = clean_coffee_df,\n",
    "    x = 'Loyalty Card',\n",
    "    y = 'Quantity',\n",
    "    hue = 'Loyalty Card',       \n",
    "    legend = False,             \n",
    "    jitter = 0.3,\n",
    "    size = 6,\n",
    "    marker = 'o',\n",
    "    edgecolor = 'auto',\n",
    "    linewidth = 0.5,\n",
    "    palette = 'Set2'\n",
    ")\n",
    "\n",
    "plt.title('Quantity Ordered by Loyalty Card Ownership')\n",
    "plt.xlabel('Loyalty Card')\n",
    "plt.ylabel('Quantity Ordered')\n",
    "plt.grid(True, axis = 'y', linestyle = '--', alpha = 0.4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f6e891",
   "metadata": {},
   "source": [
    "**Figure n.**\n",
    "\n",
    "The dot plot shows the distribution of coffee bean quantities ordered by customers, grouped by loyalty card ownership. Each dot represents a single transaction, with the quantity ordered on the y-axis and the loyalty card status on the x-axis.\n",
    "\n",
    "As seen in the figure, loyalty card owners and non-owners display similar ordering patterns. This diagram aligns with the t-test results, which show no significant difference in mean quantity ordered between the groups (t = -1.3518, p = 0.1768)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d6d855",
   "metadata": {},
   "source": [
    "📌 **Conclusion**: There is no statistically significant evidence that loyalty card ownership influences the quantity of coffee beans ordered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dd44d7",
   "metadata": {},
   "source": [
    "While our initial analysis suggests that loyalty card ownership does not significantly affect overall purchasing behavior,  it does not directly answer whether those with loyalty cards tend to order larger quantities of coffee beans. A customer may still purchase larger quantites in order.\n",
    "\n",
    "To further investigate this, we now ask:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87971261",
   "metadata": {},
   "source": [
    "**Do loyalty card owners order in larger quantities of coffee beans compared to non-owners?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c4ada5",
   "metadata": {},
   "source": [
    "To answer this question, we use the same variables from the previous analysis:\n",
    "- **Loyalty Card**: From the `customers` dataset, indicating whether a customer has a loyalty card (True or False).\n",
    "- **Quantity**: From the `orders` dataset, representing how many units of coffee beans were ordered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24ebd19",
   "metadata": {},
   "source": [
    "We will also use the same groupings from the initial analysis:\n",
    "- `owners`: Customers who have a loyalty card (Loyalty Card == 'True')\n",
    "- `non_owners`: Customers who do not have a loyalty card (Loyalty Card == 'False')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654a490a",
   "metadata": {},
   "source": [
    "To investigate this, we will conduct a **One-tailed Independent Samples T-test** to determine if loyalty card owners purchase in larger amounts compared to non-owners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c582ee84",
   "metadata": {},
   "source": [
    "Before conducting the test, we define our hypotheses:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d97bba6",
   "metadata": {},
   "source": [
    "**Null Hypothesis (H₀)**: Loyalty card owners do not order in larger quantities than non-owners (μ₁ ≤ μ₂).\n",
    "\n",
    "**Alternative Hypothesis (Hₐ)**: Loyalty card owners order in larger quantities than non-owners (μ₁ > μ₂).\n",
    "\n",
    "We will use a One-tailed Independent Samples T-test to determine if loyalty card owners order significantly more coffee beans than non-owners, based on the T-statistic and p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713ffdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stat, p_value_two_tailed = ttest_ind(owners, non_owners, equal_var=False)\n",
    "p_value_one_tailed = p_value_two_tailed / 2\n",
    "\n",
    "print(f\"Owners Mean Quantity (True): {owners.mean():.2f}\")\n",
    "print(f\"Non-Owners Mean Quantity (False): {non_owners.mean():.2f}\")\n",
    "print(f\"T-statistic: {t_stat:.4f}\")\n",
    "print(f\"One-tailed P-value: {p_value_one_tailed:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361e23f6",
   "metadata": {},
   "source": [
    "Thhe **One-tailed p-value** is **0.0884**, which is greater than **0.05**. This means the result is **not statistically significant**. \n",
    "\n",
    "Therefore, we **fail to reject the null hypothesis**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbc4ae2",
   "metadata": {},
   "source": [
    "This relationship is also shown in the bar plot below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e37a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 6))\n",
    "sns.barplot(\n",
    "    data = clean_coffee_df,\n",
    "    x = 'Loyalty Card',\n",
    "    y = 'Quantity',\n",
    "    hue = 'Loyalty Card',   \n",
    "    palette = 'Set2',\n",
    "    legend = False          \n",
    ")\n",
    "plt.title(\"Average Quantity Ordered by Loyalty Card Ownership\")\n",
    "plt.xlabel(\"Loyalty Card\")\n",
    "plt.ylabel(\"Mean Quantity Ordered\")\n",
    "plt.grid(True, axis = 'y', linestyle = '--', alpha = 0.4)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d659a1",
   "metadata": {},
   "source": [
    "**Figure n.**\n",
    "\n",
    "The bar plot displays the average quantity of coffee beans ordered by customers, grouped by loyalty card ownership. Each bar represents the mean quantity ordered for each group.\n",
    "\n",
    "As shown above, loyalty card owners do not appear to order larger quantities than non-owners. It supports the one-tailed t-test result, which found no significant evidence to support the claim that loyalty card owners order in greater quantities (t = -1.3518, one-tailed p = 0.0884)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f8b444",
   "metadata": {},
   "source": [
    "📌 **Conclusion**: There is insufficient evidence to conclude that loyalty card owners order in larger quantities of coffee beans compared to non-owners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648df10e",
   "metadata": {},
   "source": [
    "// INSERT TRANSITIONAL STATEMENT HERE\n",
    "\n",
    "### _`\"Do the coffee products with higher unit prices generate more profit?\"`_ ☕💰✨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f18ce8",
   "metadata": {},
   "source": [
    "In this analysis, we aim to determine whether there is a statistical relationship between the **unit price** of coffee products and their **total profit**. Specifically, we want to know if products with higher prices tend to generate more profit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1559daf",
   "metadata": {},
   "source": [
    "To answer this question, we focus on the following variables from the `products` dataset:\n",
    "\n",
    "- **Unit Price**: The retail price per unit of each coffee product.\n",
    "- **Profit**: The total profit associated with each product."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fc01ae",
   "metadata": {},
   "source": [
    "To assess this, we will use the **Pearson correlation coefficient**, which measures the strength and direction of a linear relationship between two continuous variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efe9c9f",
   "metadata": {},
   "source": [
    "Before conducting the test, we define our hypotheses:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceac123",
   "metadata": {},
   "source": [
    "**Null Hypothesis (H₀)**: There is no linear correlation between unit price and profit.  \n",
    "**Alternative Hypothesis (Hₐ)**: There is a significant linear correlation between unit price and profit.\n",
    "\n",
    "We will calculate the Pearson correlation coefficient and interpret both the correlation value and the associated p-value to determine if the result is statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db216f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr, p_value = pearsonr(products['Unit Price'], products['Profit'])\n",
    "\n",
    "print(f\"Pearson correlation: {corr:.3f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bd8b64",
   "metadata": {},
   "source": [
    "The Pearson correlation coefficient between **Unit Price** and **Profit** is **0.939**, indicating a **very strong positive linear relationship**. \n",
    "\n",
    "Additionally, the **p-value is less than 0.05** (p = 0.0000), which means the result is **statistically significant**. Therefore, we **reject the null hypothesis**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e443c70a",
   "metadata": {},
   "source": [
    "The following scatterplot further illustrates this relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dccadad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.regplot(data=products, x='Unit Price', y='Profit', color='teal', line_kws={\"color\": \"red\"})\n",
    "\n",
    "plt.title('Scatterplot of Unit Price vs Profit')\n",
    "plt.xlabel('Unit Price')\n",
    "plt.ylabel('Profit')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd72863",
   "metadata": {},
   "source": [
    "**Figure 1.**  \n",
    "The scatterplot displays the relationship between **Unit Price** and **Profit** for each coffee product in the dataset. Each teal point represents a product, with its unit price on the x-axis and the corresponding profit on the y-axis.\n",
    "\n",
    "The red regression line illustrates the overall linear trend. As shown, products with higher unit prices tend to generate higher profits, confirming the positive relationship observed in the Pearson correlation analysis (r = 0.939, p < 0.001)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bdb975",
   "metadata": {},
   "source": [
    "📌 **Conclusion**: There exists a statistically significant linear correlation between unit price and profit among coffee products."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534c108b",
   "metadata": {},
   "source": [
    "While our initial analysis shows a strong positive correlation between unit price and profit, this does not account for how well each product actually sells. High-priced items may yield high per-unit profits, but low sales volumes could limit their total profitability. To explore this further, we now ask:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69059526",
   "metadata": {},
   "source": [
    "**Do sales volumes influence total profit for higher-priced coffee products?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f16e2bf",
   "metadata": {},
   "source": [
    "To answer this question, we focus on the following variables:\n",
    "\n",
    "- From the `products` dataset:\n",
    "  - **Unit Price**: The retail price per unit of each coffee product.\n",
    "  - **Profit**: The total profit associated with each product.\n",
    "- From the `orders` dataset:\n",
    "  - **Quantity**: The number of units ordered per product."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996af4a5",
   "metadata": {},
   "source": [
    "This analysis will help determine whether limited demand for expensive products affects their overall contribution to profit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0bc265",
   "metadata": {},
   "source": [
    "Before conducting the test, we define our hypotheses:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bf8271",
   "metadata": {},
   "source": [
    "**Null Hypothesis (H₀)**: There is no significant linear correlation between sales volume (Quantity) and total profit for higher-priced coffee products.  \n",
    "**Alternative Hypothesis (Hₐ)**: There is a significant linear correlation between sales volume (Quantity) and total profit for higher-priced coffee products.\n",
    "\n",
    "We will calculate the Pearson correlation coefficient and evaluate the associated p-value. This will allow us to determine both the strength of the linear relationship and whether the result is statistically significant at the conventional 0.05 significance level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ee9974",
   "metadata": {},
   "source": [
    "We will use `clean_coffee_df`, a merged and cleaned dataset combining product and order details needed to compute total profit per product."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d144dc13",
   "metadata": {},
   "source": [
    "### Step 1: Group by Product\n",
    "\n",
    "We group the merged data by each product to calculate:\n",
    "- Total quantity sold\n",
    "- Per-unit profit and unit price (from `products`)\n",
    "- Total profit = Quantity × Profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c48f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = clean_coffee_df.groupby(['Product ID', 'Coffee Type', 'Roast Type']) \\\n",
    "    .agg({\n",
    "        'Quantity': 'sum',\n",
    "        'Profit': 'first',\n",
    "        'Unit Price': 'first'\n",
    "    }).reset_index()\n",
    "\n",
    "grouped['Total Profit'] = grouped['Quantity'] * grouped['Profit']\n",
    "grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5f98c9",
   "metadata": {},
   "source": [
    "### Step 2: Focus on High-Priced Products\n",
    "\n",
    "We define \"high-priced\" as products whose unit price falls in the top 25% of all products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac93ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_price = grouped['Unit Price'].quantile(0.75)\n",
    "high_priced = grouped[grouped['Unit Price'] >= q3_price]\n",
    "high_priced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005ffedd",
   "metadata": {},
   "source": [
    "### Step 3: Correlation Analysis\n",
    "\n",
    "We calculate the Pearson correlation coefficient to assess the linear relationship between **quantity sold** and **total profit** for high-priced products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f023ec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr, pval = pearsonr(high_priced['Quantity'], high_priced['Total Profit'])\n",
    "\n",
    "print(f\"Pearson correlation: {corr:.3f}\")\n",
    "print(f\"P-value: {pval:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe12d57",
   "metadata": {},
   "source": [
    "The Pearson correlation coefficient between **Quantity** and **Total Profit** for higher-priced products is **0.301**, indicating a **weak positive linear relationship**. \n",
    "\n",
    "However, the **p-value is greater than 0.05** (p = 0.3418), so the result is **not statistically significant**. Therefore, we **fail to reject the null hypothesis**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a2c941",
   "metadata": {},
   "source": [
    "#### Step 4: Visualization\n",
    "\n",
    "To visually support the correlation result, we generate a scatterplot with a regression line showing how quantity sold relates to total profit for high-priced products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fc1ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.regplot(\n",
    "    data=high_priced,\n",
    "    x='Quantity',\n",
    "    y='Total Profit',\n",
    "    color='teal',\n",
    "    line_kws={\"color\": \"red\"}\n",
    ")\n",
    "\n",
    "plt.title('Quantity Sold vs Total Profit (High-Priced Products)')\n",
    "plt.xlabel('Total Quantity Sold')\n",
    "plt.ylabel('Total Profit')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2137d12d",
   "metadata": {},
   "source": [
    "**Figure 2.**  \n",
    "The scatterplot illustrates the relationship between **quantity sold** and **total profit** for high-priced coffee products. Each teal point represents a product, where the x-axis shows the total number of units sold and the y-axis displays the corresponding total profit.\n",
    "\n",
    "The red regression line represents the overall linear trend based on Pearson correlation analysis. While there is a slight upward trend, the distribution of points appears scattered, and no strong linear relationship is visually evident.\n",
    "\n",
    "This aligns with the earlier statistical result (r = 0.301, p = 0.3418), suggesting that the correlation between sales volume and total profit among high-priced items is weak and not statistically significant. This indicates that simply pricing products higher does not guarantee greater overall profit if the products do not sell in large volumes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a9c419",
   "metadata": {},
   "source": [
    "📌 **Conclusion**: There is no statistically significant linear correlation between sales volume and total profit for high-priced coffee products."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6007c8",
   "metadata": {},
   "source": [
    "# Conclusion ✅\n",
    "\n",
    "// INSERT CONCLUSION HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
