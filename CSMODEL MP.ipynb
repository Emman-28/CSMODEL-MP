{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de097fbe",
   "metadata": {},
   "source": [
    "# CSMODEL Machine Project (Phase 1) ‚òï‚ú®\n",
    "This Jupyter Notebook was made in compliance with the requirements set by the course Statistical Modelling and Simulation (CSMODEL). \n",
    "\n",
    "This machine project was prepared by the following students from section S16:\n",
    "- Filipino, Eunice Marble R.\n",
    "- Lazaro, Heisel Janine C.\n",
    "- Punsalan, Emmanuel Gerald G.\n",
    "- Wee, Justine Erika D.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb6eb79",
   "metadata": {},
   "source": [
    "# Import Libraries ‚¨áÔ∏è\n",
    "\n",
    "The following libraries are imported to provide essential functionalities for data processing, analysis, and visualization throughout this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f500af11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\punsa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\punsa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\punsa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.14.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.23.5 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scipy) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\punsa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\punsa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\punsa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from seaborn) (2.1.1)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from seaborn) (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\punsa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\punsa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\punsa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\punsa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\punsa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\punsa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rapidfuzz in c:\\users\\punsa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.13.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openpyxl\n",
    "%pip install scipy\n",
    "%pip install seaborn\n",
    "%pip install rapidfuzz\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import ttest_ind\n",
    "from rapidfuzz import process, fuzz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e697f317",
   "metadata": {},
   "source": [
    "# Data Description ‚ÑπÔ∏è‚ú®\n",
    "The [Coffee Bean Sales Dataset](https://www.kaggle.com/datasets/saadharoon27/coffee-bean-sales-raw-dataset/data) provides comprehensive insights into the coffee industry. It contains detailed information on coffee orders, customer profiles and product details. The dataset is divided into three worksheets, providing specific information about orders, customers and products. The orders worksheet reflects the coffee transactions made by customers. The customers worksheet contains specific details on the customers. Lastly, the products worksheet details each coffee product."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbf49a7",
   "metadata": {},
   "source": [
    "### How the data was collected\n",
    "\n",
    "The dataset was acquired from [Kaggle](https://www.kaggle.com) which houses datasets that may be from open sources, web scraping, or simulations. It is not outwardly stated how the coffee bean sales dataset was gathered, but it can be assumed that it was artificially generated for educational purposes due to the lack of details and metadata surrounding the orders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7a6890",
   "metadata": {},
   "source": [
    "### Potential Implications\n",
    "\n",
    "As the data was collected through unknown sources, there are potential implications on how information was recorded. The lack of standardization across dataset fields may lead to discrepancies, inconsistencies, or misleading conclusions during data analysis. Additionally, the lack of metadata challenges to determine the scope of the dataset‚Äîincreasing the risk of sampling bias. It also imposes constraints in preprocessing since the dataset was provided in a pre-cleaned format; hence, further restricting the accuracy and relevance of the insights that will be generated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1981d246",
   "metadata": {},
   "source": [
    "### Dataset Overview (Structure and Attributes)\n",
    "\n",
    "The dataset is divided into three worksheets, which are the following:\n",
    "\n",
    "üìÉ **Orders:** Consists of **1,000 observations** and **9 variables**, where each observation represents an order. The attributes of which include:\n",
    "\n",
    "| **Attribute** | **Description**                              |\n",
    "|---------------|----------------------------------------------|\n",
    "| **Order ID**  | A unique identifier for each order           |\n",
    "| **Order Date**| The date the order was placed                |\n",
    "| **Customer ID** | A reference to the customer who placed the order |\n",
    "| **Product ID** | A reference to the product ordered          |\n",
    "| **Quantity**  | The number of units ordered                  |\n",
    "\n",
    "üßë **Customers:** Consists of **1,000 observations** and **9 variables**, where each observation represents a distinct customer. The attributes of which include:\n",
    "\n",
    "| **Attribute**     | **Description**                        |\n",
    "|-------------------|----------------------------------------|\n",
    "| **Customer ID**   | A unique identifier for each customer  |\n",
    "| **Customer Name** | The full name of the customer          |\n",
    "| **Email Address** | Contact email of the customer          |\n",
    "| **Phone Number**  | Customer‚Äôs phone contact               |\n",
    "| **Address Line 1**  | Primary street address of the customer |\n",
    "| **City**            | City of the customer‚Äôs address         |\n",
    "| **Country**         | Country of residence                   |\n",
    "| **Postcode**        | Postal/ZIP code of the customer‚Äôs address |\n",
    "| **Loyalty Card**    | Indicates whether the customer has a loyalty card (Yes/No) |\n",
    "\n",
    "‚òï **Products:** Consists of **48 observations** and **7 variables**, where each observation represents a unique coffee product. The attributes of which include:\n",
    "\n",
    "| **Attribute**     | **Description**                                     |\n",
    "|-------------------|--------------------------------------------------- |\n",
    "| **Product ID**    | A unique identifier for each product                |\n",
    "| **Coffee Type**   | The blend or type of coffee (e.g., Arabica, Robusta)|\n",
    "| **Roast Type**    | The level of roast (e.g., light, medium, dark)      |\n",
    "| **Size**          | Packaging size of the product                      |\n",
    "| **Unit Price**    | Retail price per unit                              |\n",
    "| **Price per 100g**| Standardized pricing for comparison                |\n",
    "| **Profit**        | Profitability of each product                      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fc7aa1",
   "metadata": {},
   "source": [
    "# Reading the Dataset üìù\n",
    "\n",
    "With all that in mind, let's load in the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eef40947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Excel file\n",
    "file_path = 'Coffee Bean Dataset.xlsx'\n",
    "\n",
    "# Loading each worksheet into a separate DataFrame\n",
    "orders = pd.read_excel(file_path, sheet_name = 'orders')\n",
    "customers = pd.read_excel(file_path, sheet_name = 'customers')\n",
    "products = pd.read_excel(file_path, sheet_name = 'products')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60be8cd",
   "metadata": {},
   "source": [
    "We should take a peek into the three worksheets to confirm our loading worked... üëÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caaaaf6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Email</th>\n",
       "      <th>Country</th>\n",
       "      <th>Coffee Type</th>\n",
       "      <th>Roast Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>Unit Price</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QEV-37451-860</td>\n",
       "      <td>2019-09-05</td>\n",
       "      <td>17670-51384-MA</td>\n",
       "      <td>R-M-1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QEV-37451-860</td>\n",
       "      <td>2019-09-05</td>\n",
       "      <td>17670-51384-MA</td>\n",
       "      <td>E-M-0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FAA-43335-268</td>\n",
       "      <td>2021-06-17</td>\n",
       "      <td>21125-22134-PX</td>\n",
       "      <td>A-L-1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KAC-83089-793</td>\n",
       "      <td>2021-07-15</td>\n",
       "      <td>23806-46781-OU</td>\n",
       "      <td>E-M-1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KAC-83089-793</td>\n",
       "      <td>2021-07-15</td>\n",
       "      <td>23806-46781-OU</td>\n",
       "      <td>R-L-2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Order ID Order Date     Customer ID Product ID  Quantity  \\\n",
       "0  QEV-37451-860 2019-09-05  17670-51384-MA      R-M-1         2   \n",
       "1  QEV-37451-860 2019-09-05  17670-51384-MA    E-M-0.5         5   \n",
       "2  FAA-43335-268 2021-06-17  21125-22134-PX      A-L-1         1   \n",
       "3  KAC-83089-793 2021-07-15  23806-46781-OU      E-M-1         2   \n",
       "4  KAC-83089-793 2021-07-15  23806-46781-OU    R-L-2.5         2   \n",
       "\n",
       "   Customer Name  Email  Country  Coffee Type  Roast Type  Size  Unit Price  \\\n",
       "0            NaN    NaN      NaN          NaN         NaN   NaN         NaN   \n",
       "1            NaN    NaN      NaN          NaN         NaN   NaN         NaN   \n",
       "2            NaN    NaN      NaN          NaN         NaN   NaN         NaN   \n",
       "3            NaN    NaN      NaN          NaN         NaN   NaN         NaN   \n",
       "4            NaN    NaN      NaN          NaN         NaN   NaN         NaN   \n",
       "\n",
       "   Sales  \n",
       "0    NaN  \n",
       "1    NaN  \n",
       "2    NaN  \n",
       "3    NaN  \n",
       "4    NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60b247b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Email</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Address Line 1</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Loyalty Card</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17670-51384-MA</td>\n",
       "      <td>Aloisia Allner</td>\n",
       "      <td>aallner0@lulu.com</td>\n",
       "      <td>+1 (862) 817-0124</td>\n",
       "      <td>57999 Pepper Wood Alley</td>\n",
       "      <td>Paterson</td>\n",
       "      <td>United States</td>\n",
       "      <td>7505</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73342-18763-UW</td>\n",
       "      <td>Piotr Bote</td>\n",
       "      <td>pbote1@yelp.com</td>\n",
       "      <td>+353 (913) 396-4653</td>\n",
       "      <td>2112 Ridgeway Hill</td>\n",
       "      <td>Crumlin</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>D6W</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21125-22134-PX</td>\n",
       "      <td>Jami Redholes</td>\n",
       "      <td>jredholes2@tmall.com</td>\n",
       "      <td>+1 (210) 986-6806</td>\n",
       "      <td>5214 Bartillon Park</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>United States</td>\n",
       "      <td>78205</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71253-00052-RN</td>\n",
       "      <td>Dene Azema</td>\n",
       "      <td>dazema3@facebook.com</td>\n",
       "      <td>+1 (217) 418-0714</td>\n",
       "      <td>27 Maywood Place</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>United States</td>\n",
       "      <td>62711</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23806-46781-OU</td>\n",
       "      <td>Christoffer O' Shea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+353 (698) 362-9201</td>\n",
       "      <td>38980 Manitowish Junction</td>\n",
       "      <td>Cill Airne</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>N41</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Customer ID        Customer Name                 Email  \\\n",
       "0  17670-51384-MA       Aloisia Allner     aallner0@lulu.com   \n",
       "1  73342-18763-UW           Piotr Bote       pbote1@yelp.com   \n",
       "2  21125-22134-PX        Jami Redholes  jredholes2@tmall.com   \n",
       "3  71253-00052-RN           Dene Azema  dazema3@facebook.com   \n",
       "4  23806-46781-OU  Christoffer O' Shea                   NaN   \n",
       "\n",
       "          Phone Number             Address Line 1         City        Country  \\\n",
       "0    +1 (862) 817-0124    57999 Pepper Wood Alley     Paterson  United States   \n",
       "1  +353 (913) 396-4653         2112 Ridgeway Hill      Crumlin        Ireland   \n",
       "2    +1 (210) 986-6806        5214 Bartillon Park  San Antonio  United States   \n",
       "3    +1 (217) 418-0714           27 Maywood Place  Springfield  United States   \n",
       "4  +353 (698) 362-9201  38980 Manitowish Junction   Cill Airne        Ireland   \n",
       "\n",
       "  Postcode Loyalty Card  \n",
       "0     7505          Yes  \n",
       "1      D6W           No  \n",
       "2    78205          Yes  \n",
       "3    62711          Yes  \n",
       "4      N41           No  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbb36ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Coffee Type</th>\n",
       "      <th>Roast Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>Unit Price</th>\n",
       "      <th>Price per 100g</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-L-0.2</td>\n",
       "      <td>Ara</td>\n",
       "      <td>L</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.885</td>\n",
       "      <td>1.9425</td>\n",
       "      <td>0.34965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A-L-0.5</td>\n",
       "      <td>Ara</td>\n",
       "      <td>L</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.770</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>0.69930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A-L-1</td>\n",
       "      <td>Ara</td>\n",
       "      <td>L</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.950</td>\n",
       "      <td>1.2950</td>\n",
       "      <td>1.16550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-L-2.5</td>\n",
       "      <td>Ara</td>\n",
       "      <td>L</td>\n",
       "      <td>2.5</td>\n",
       "      <td>29.785</td>\n",
       "      <td>1.1914</td>\n",
       "      <td>2.68065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A-M-0.2</td>\n",
       "      <td>Ara</td>\n",
       "      <td>M</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.375</td>\n",
       "      <td>1.6875</td>\n",
       "      <td>0.30375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Product ID Coffee Type Roast Type  Size  Unit Price  Price per 100g   Profit\n",
       "0    A-L-0.2         Ara          L   0.2       3.885          1.9425  0.34965\n",
       "1    A-L-0.5         Ara          L   0.5       7.770          1.5540  0.69930\n",
       "2      A-L-1         Ara          L   1.0      12.950          1.2950  1.16550\n",
       "3    A-L-2.5         Ara          L   2.5      29.785          1.1914  2.68065\n",
       "4    A-M-0.2         Ara          M   0.2       3.375          1.6875  0.30375"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09a449d",
   "metadata": {},
   "source": [
    "Eureka! The Coffee Bean Dataset has loaded into our Notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164d3aa6",
   "metadata": {},
   "source": [
    "But each worksheet only gives us partial information about the data... So, let's join the worksheets together to gain more insights! üîç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cdd17b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging Orders with Customers on 'Customer ID'\n",
    "orders_customers = pd.merge(orders, customers, on = 'Customer ID', how = 'left')\n",
    "\n",
    "# Merging the result with Products on 'Product ID'\n",
    "coffee_df = pd.merge(orders_customers, products, on = 'Product ID', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e6dc56",
   "metadata": {},
   "source": [
    "Let's take another peek but now into the merged dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bfae213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 27 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   Order ID         1000 non-null   object        \n",
      " 1   Order Date       1000 non-null   datetime64[ns]\n",
      " 2   Customer ID      1000 non-null   object        \n",
      " 3   Product ID       1000 non-null   object        \n",
      " 4   Quantity         1000 non-null   int64         \n",
      " 5   Customer Name_x  0 non-null      float64       \n",
      " 6   Email_x          0 non-null      float64       \n",
      " 7   Country_x        0 non-null      float64       \n",
      " 8   Coffee Type_x    0 non-null      float64       \n",
      " 9   Roast Type_x     0 non-null      float64       \n",
      " 10  Size_x           0 non-null      float64       \n",
      " 11  Unit Price_x     0 non-null      float64       \n",
      " 12  Sales            0 non-null      float64       \n",
      " 13  Customer Name_y  1000 non-null   object        \n",
      " 14  Email_y          794 non-null    object        \n",
      " 15  Phone Number     865 non-null    object        \n",
      " 16  Address Line 1   1000 non-null   object        \n",
      " 17  City             1000 non-null   object        \n",
      " 18  Country_y        1000 non-null   object        \n",
      " 19  Postcode         1000 non-null   object        \n",
      " 20  Loyalty Card     1000 non-null   object        \n",
      " 21  Coffee Type_y    1000 non-null   object        \n",
      " 22  Roast Type_y     1000 non-null   object        \n",
      " 23  Size_y           1000 non-null   float64       \n",
      " 24  Unit Price_y     1000 non-null   float64       \n",
      " 25  Price per 100g   1000 non-null   float64       \n",
      " 26  Profit           1000 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(12), int64(1), object(13)\n",
      "memory usage: 211.1+ KB\n"
     ]
    }
   ],
   "source": [
    "coffee_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33faddc",
   "metadata": {},
   "source": [
    "We're all set! We can now proceed to cleaning the dataset. ü´ß"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bec60b5",
   "metadata": {},
   "source": [
    "# Data Cleaning üßπ‚ú® \n",
    "\n",
    "Before performing analysis, it is essential to clean the dataset so we ensure accuracy and reliability of results. We'll be handling variables and values with **multiple representations**, **incorrect datatypes**, **missing data**, **duplicate data**, **inconsistent formatting**, and **outliers**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf7674e",
   "metadata": {},
   "source": [
    "Let's look at the dataset and its variables again! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49830000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 27 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   Order ID         1000 non-null   object        \n",
      " 1   Order Date       1000 non-null   datetime64[ns]\n",
      " 2   Customer ID      1000 non-null   object        \n",
      " 3   Product ID       1000 non-null   object        \n",
      " 4   Quantity         1000 non-null   int64         \n",
      " 5   Customer Name_x  0 non-null      float64       \n",
      " 6   Email_x          0 non-null      float64       \n",
      " 7   Country_x        0 non-null      float64       \n",
      " 8   Coffee Type_x    0 non-null      float64       \n",
      " 9   Roast Type_x     0 non-null      float64       \n",
      " 10  Size_x           0 non-null      float64       \n",
      " 11  Unit Price_x     0 non-null      float64       \n",
      " 12  Sales            0 non-null      float64       \n",
      " 13  Customer Name_y  1000 non-null   object        \n",
      " 14  Email_y          794 non-null    object        \n",
      " 15  Phone Number     865 non-null    object        \n",
      " 16  Address Line 1   1000 non-null   object        \n",
      " 17  City             1000 non-null   object        \n",
      " 18  Country_y        1000 non-null   object        \n",
      " 19  Postcode         1000 non-null   object        \n",
      " 20  Loyalty Card     1000 non-null   object        \n",
      " 21  Coffee Type_y    1000 non-null   object        \n",
      " 22  Roast Type_y     1000 non-null   object        \n",
      " 23  Size_y           1000 non-null   float64       \n",
      " 24  Unit Price_y     1000 non-null   float64       \n",
      " 25  Price per 100g   1000 non-null   float64       \n",
      " 26  Profit           1000 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(12), int64(1), object(13)\n",
      "memory usage: 211.1+ KB\n"
     ]
    }
   ],
   "source": [
    "coffee_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef19247f",
   "metadata": {},
   "source": [
    "There's a lot of variables we don't need as a result of merging. We can drop those. Goodbye! üëã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29c301cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Email</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Address Line 1</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Loyalty Card</th>\n",
       "      <th>Coffee Type</th>\n",
       "      <th>Roast Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>Unit Price</th>\n",
       "      <th>Price per 100g</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QEV-37451-860</td>\n",
       "      <td>2019-09-05</td>\n",
       "      <td>17670-51384-MA</td>\n",
       "      <td>R-M-1</td>\n",
       "      <td>2</td>\n",
       "      <td>Aloisia Allner</td>\n",
       "      <td>aallner0@lulu.com</td>\n",
       "      <td>+1 (862) 817-0124</td>\n",
       "      <td>57999 Pepper Wood Alley</td>\n",
       "      <td>Paterson</td>\n",
       "      <td>United States</td>\n",
       "      <td>7505</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Rob</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.950</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>0.5970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QEV-37451-860</td>\n",
       "      <td>2019-09-05</td>\n",
       "      <td>17670-51384-MA</td>\n",
       "      <td>E-M-0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>Aloisia Allner</td>\n",
       "      <td>aallner0@lulu.com</td>\n",
       "      <td>+1 (862) 817-0124</td>\n",
       "      <td>57999 Pepper Wood Alley</td>\n",
       "      <td>Paterson</td>\n",
       "      <td>United States</td>\n",
       "      <td>7505</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Exc</td>\n",
       "      <td>M</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.250</td>\n",
       "      <td>1.6500</td>\n",
       "      <td>0.9075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FAA-43335-268</td>\n",
       "      <td>2021-06-17</td>\n",
       "      <td>21125-22134-PX</td>\n",
       "      <td>A-L-1</td>\n",
       "      <td>1</td>\n",
       "      <td>Jami Redholes</td>\n",
       "      <td>jredholes2@tmall.com</td>\n",
       "      <td>+1 (210) 986-6806</td>\n",
       "      <td>5214 Bartillon Park</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>United States</td>\n",
       "      <td>78205</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Ara</td>\n",
       "      <td>L</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.950</td>\n",
       "      <td>1.2950</td>\n",
       "      <td>1.1655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KAC-83089-793</td>\n",
       "      <td>2021-07-15</td>\n",
       "      <td>23806-46781-OU</td>\n",
       "      <td>E-M-1</td>\n",
       "      <td>2</td>\n",
       "      <td>Christoffer O' Shea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+353 (698) 362-9201</td>\n",
       "      <td>38980 Manitowish Junction</td>\n",
       "      <td>Cill Airne</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>N41</td>\n",
       "      <td>No</td>\n",
       "      <td>Exc</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.750</td>\n",
       "      <td>1.3750</td>\n",
       "      <td>1.5125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KAC-83089-793</td>\n",
       "      <td>2021-07-15</td>\n",
       "      <td>23806-46781-OU</td>\n",
       "      <td>R-L-2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>Christoffer O' Shea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+353 (698) 362-9201</td>\n",
       "      <td>38980 Manitowish Junction</td>\n",
       "      <td>Cill Airne</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>N41</td>\n",
       "      <td>No</td>\n",
       "      <td>Rob</td>\n",
       "      <td>L</td>\n",
       "      <td>2.5</td>\n",
       "      <td>27.485</td>\n",
       "      <td>1.0994</td>\n",
       "      <td>1.6491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Order ID Order Date     Customer ID Product ID  Quantity  \\\n",
       "0  QEV-37451-860 2019-09-05  17670-51384-MA      R-M-1         2   \n",
       "1  QEV-37451-860 2019-09-05  17670-51384-MA    E-M-0.5         5   \n",
       "2  FAA-43335-268 2021-06-17  21125-22134-PX      A-L-1         1   \n",
       "3  KAC-83089-793 2021-07-15  23806-46781-OU      E-M-1         2   \n",
       "4  KAC-83089-793 2021-07-15  23806-46781-OU    R-L-2.5         2   \n",
       "\n",
       "         Customer Name                 Email         Phone Number  \\\n",
       "0       Aloisia Allner     aallner0@lulu.com    +1 (862) 817-0124   \n",
       "1       Aloisia Allner     aallner0@lulu.com    +1 (862) 817-0124   \n",
       "2        Jami Redholes  jredholes2@tmall.com    +1 (210) 986-6806   \n",
       "3  Christoffer O' Shea                   NaN  +353 (698) 362-9201   \n",
       "4  Christoffer O' Shea                   NaN  +353 (698) 362-9201   \n",
       "\n",
       "              Address Line 1         City        Country Postcode  \\\n",
       "0    57999 Pepper Wood Alley     Paterson  United States     7505   \n",
       "1    57999 Pepper Wood Alley     Paterson  United States     7505   \n",
       "2        5214 Bartillon Park  San Antonio  United States    78205   \n",
       "3  38980 Manitowish Junction   Cill Airne        Ireland      N41   \n",
       "4  38980 Manitowish Junction   Cill Airne        Ireland      N41   \n",
       "\n",
       "  Loyalty Card Coffee Type Roast Type  Size  Unit Price  Price per 100g  \\\n",
       "0          Yes         Rob          M   1.0       9.950          0.9950   \n",
       "1          Yes         Exc          M   0.5       8.250          1.6500   \n",
       "2          Yes         Ara          L   1.0      12.950          1.2950   \n",
       "3           No         Exc          M   1.0      13.750          1.3750   \n",
       "4           No         Rob          L   2.5      27.485          1.0994   \n",
       "\n",
       "   Profit  \n",
       "0  0.5970  \n",
       "1  0.9075  \n",
       "2  1.1655  \n",
       "3  1.5125  \n",
       "4  1.6491  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping the useless columns\n",
    "columns_to_drop = [\n",
    "    'Customer Name_x', \n",
    "    'Email_x', \n",
    "    'Country_x', \n",
    "    'Coffee Type_x', \n",
    "    'Roast Type_x', \n",
    "    'Size_x', \n",
    "    'Unit Price_x', \n",
    "    'Sales']\n",
    "clean_coffee_df = coffee_df.drop(columns = columns_to_drop)\n",
    "\n",
    "# Renaming remaining columns for clarity\n",
    "clean_coffee_df = clean_coffee_df.rename(columns = {\n",
    "    'Customer Name_y': 'Customer Name',\n",
    "    'Email_y': 'Email',\n",
    "    'Country_y': 'Country',\n",
    "    'Coffee Type_y': 'Coffee Type',\n",
    "    'Roast Type_y': 'Roast Type',\n",
    "    'Size_y': 'Size',\n",
    "    'Unit Price_y': 'Unit Price'\n",
    "})\n",
    "\n",
    "clean_coffee_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67347ea",
   "metadata": {},
   "source": [
    "Looking good so far! We can now proceed to cleaning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81705efa",
   "metadata": {},
   "source": [
    "### Incorrect Datatypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a5a119",
   "metadata": {},
   "source": [
    "Incorrect Datatypes happen when the type of data stored in a column doesn‚Äôt match what it should be for correct analysis or operations. \n",
    "\n",
    "Strings shouldn't be stored as Floats! Dates shouldn't be stored as plain text... We might run into problems for computing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f35701",
   "metadata": {},
   "source": [
    "Here's code to generate table with their current datatypes! The \"Pandas Type\" column refers to their datatype in terms of Pandas, while the \"Python Type\" column refers to their specific datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c03eddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Attribute     Pandas Type Python Type\n",
      "0         Order ID          object         str\n",
      "1       Order Date  datetime64[ns]   Timestamp\n",
      "2      Customer ID          object         str\n",
      "3       Product ID          object         str\n",
      "4         Quantity           int64       int64\n",
      "5    Customer Name          object         str\n",
      "6            Email          object         str\n",
      "7     Phone Number          object         str\n",
      "8   Address Line 1          object         str\n",
      "9             City          object         str\n",
      "10         Country          object         str\n",
      "11        Postcode          object         int\n",
      "12    Loyalty Card          object         str\n",
      "13     Coffee Type          object         str\n",
      "14      Roast Type          object         str\n",
      "15            Size         float64     float64\n",
      "16      Unit Price         float64     float64\n",
      "17  Price per 100g         float64     float64\n",
      "18          Profit         float64     float64\n"
     ]
    }
   ],
   "source": [
    "# Preparing the table data\n",
    "data = []\n",
    "\n",
    "for column in clean_coffee_df.columns:\n",
    "    # Drop NA to avoid errors when accessing the first element\n",
    "    first_value = clean_coffee_df[column].dropna().iloc[0] if not clean_coffee_df[column].dropna().empty else None\n",
    "    python_type = type(first_value).__name__ if first_value is not None else 'NoneType'\n",
    "    \n",
    "    data.append({\n",
    "        'Attribute': column,\n",
    "        'Pandas Type': str(clean_coffee_df[column].dtype),\n",
    "        'Python Type': python_type\n",
    "    })\n",
    "\n",
    "# Converting to DataFrame for display\n",
    "dtype_table = pd.DataFrame(data)\n",
    "print(dtype_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771f2e81",
   "metadata": {},
   "source": [
    "Unique identifiers like the Order ID, Customer ID, and Product ID are stored as objects, specifically strings. No problems here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61eb7d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(clean_coffee_df['Order ID'].iloc[0]))\n",
    "print(type(clean_coffee_df['Customer ID'].iloc[0]))\n",
    "print(type(clean_coffee_df['Product ID'].iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865bf661",
   "metadata": {},
   "source": [
    "Order Dates are stored as objects, specifically a datetime date. All good on this end!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48b60049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n"
     ]
    }
   ],
   "source": [
    "print(type(clean_coffee_df['Order Date'].iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34ab19b",
   "metadata": {},
   "source": [
    "On that note, textual information like the Customer Name, Email, Address Line 1, City, Country, Phone Numbers, and Postcodes should be strings also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a397a0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(clean_coffee_df['Customer Name'].iloc[0]))\n",
    "print(type(clean_coffee_df['Email'].iloc[0]))\n",
    "print(type(clean_coffee_df['Address Line 1'].iloc[0]))\n",
    "print(type(clean_coffee_df['City'].iloc[0]))\n",
    "print(type(clean_coffee_df['Country'].iloc[0]))\n",
    "print(type(clean_coffee_df['Phone Number'].iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9fdfdf",
   "metadata": {},
   "source": [
    "Oh no! All the other variables are correct but Postcodes are represented as ints, so let's fix that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "daeb5d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_coffee_df['Postcode'] = clean_coffee_df['Postcode'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f02c50ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(clean_coffee_df['Postcode'].iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bf2c14",
   "metadata": {},
   "source": [
    "The Loyalty Card variable is filled with \"Yes\" and \"No\", but it would be much better to analyze boolean values. Would that be true or false?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9548bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_coffee_df['Loyalty Card'] = clean_coffee_df['Loyalty Card'].map({'Yes': True, 'No': False}).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4830b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.bool'>\n"
     ]
    }
   ],
   "source": [
    "print(type(clean_coffee_df['Loyalty Card'].iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b0cb83",
   "metadata": {},
   "source": [
    "Numerical information like Unit Price, Price per 100g, Profit, Size, and Quantity are already floats and int respectively. No need for corrections!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2eb97cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "print(type(clean_coffee_df['Unit Price'].iloc[0]))\n",
    "print(type(clean_coffee_df['Price per 100g'].iloc[0]))\n",
    "print(type(clean_coffee_df['Profit'].iloc[0]))\n",
    "print(type(clean_coffee_df['Size'].iloc[0]))\n",
    "print(type(clean_coffee_df['Quantity'].iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3358fa",
   "metadata": {},
   "source": [
    "Information that uses the same set of values can be identified into categories. For the Coffee Type, Roast Type, and Size, we can convert them to the category datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7607115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_coffee_df['Coffee Type'] = clean_coffee_df['Coffee Type'].astype('category')\n",
    "clean_coffee_df['Roast Type'] = clean_coffee_df['Roast Type'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f024db65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "category\n"
     ]
    }
   ],
   "source": [
    "print(clean_coffee_df['Coffee Type'].dtype)\n",
    "print(clean_coffee_df['Roast Type'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e83273",
   "metadata": {},
   "source": [
    "Let's take another look to check all the datatypes for the last time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96cbc714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Attribute     Pandas Type Python Type\n",
      "0         Order ID          object         str\n",
      "1       Order Date  datetime64[ns]   Timestamp\n",
      "2      Customer ID          object         str\n",
      "3       Product ID          object         str\n",
      "4         Quantity           int64       int64\n",
      "5    Customer Name          object         str\n",
      "6            Email          object         str\n",
      "7     Phone Number          object         str\n",
      "8   Address Line 1          object         str\n",
      "9             City          object         str\n",
      "10         Country          object         str\n",
      "11        Postcode          object         str\n",
      "12    Loyalty Card            bool        bool\n",
      "13     Coffee Type        category         str\n",
      "14      Roast Type        category         str\n",
      "15            Size         float64     float64\n",
      "16      Unit Price         float64     float64\n",
      "17  Price per 100g         float64     float64\n",
      "18          Profit         float64     float64\n"
     ]
    }
   ],
   "source": [
    "# Preparing the table data\n",
    "data = []\n",
    "\n",
    "for column in clean_coffee_df.columns:\n",
    "    # Drop NA to avoid errors when accessing the first element\n",
    "    first_value = clean_coffee_df[column].dropna().iloc[0] if not clean_coffee_df[column].dropna().empty else None\n",
    "    python_type = type(first_value).__name__ if first_value is not None else 'NoneType'\n",
    "    \n",
    "    data.append({\n",
    "        'Attribute': column,\n",
    "        'Pandas Type': str(clean_coffee_df[column].dtype),\n",
    "        'Python Type': python_type\n",
    "    })\n",
    "\n",
    "# Converting to DataFrame for display\n",
    "dtype_table = pd.DataFrame(data)\n",
    "print(dtype_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927ae8ac",
   "metadata": {},
   "source": [
    "We're all set, the datatypes now fit the variables! Good job! üëè"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b7e0e3",
   "metadata": {},
   "source": [
    "### Multiple Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f385e0d2",
   "metadata": {},
   "source": [
    "Some observations may have the same value but presented differently. That's what we call \"Multiple Representations\"\n",
    "\n",
    "Just as an example, there are observations in Country \"U.S.A\", \"United States of America\", and \"USA\". That's too many! We have make America consistent again! ü¶Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171de211",
   "metadata": {},
   "source": [
    "We can start with the categorical variables since they're expected to be consistent all throughout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00f4c507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rob', 'Exc', 'Ara', 'Lib']\n",
      "Categories (4, object): ['Ara', 'Exc', 'Lib', 'Rob']\n",
      "['M', 'L', 'D']\n",
      "Categories (3, object): ['D', 'L', 'M']\n"
     ]
    }
   ],
   "source": [
    "print(clean_coffee_df['Coffee Type'].unique())\n",
    "print(clean_coffee_df['Roast Type'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e067c9",
   "metadata": {},
   "source": [
    "There are 4 distinct objects for Coffee Type and there are no duplicates among the values found, same goes with the Roast Type. So, we can conclude that there are no multiple representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3511d6",
   "metadata": {},
   "source": [
    "Same logic goes for the Country variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e940dd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['United States' 'Ireland' 'United Kingdom']\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(clean_coffee_df['Country'].unique())\n",
    "print(clean_coffee_df['Country'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886a0d81",
   "metadata": {},
   "source": [
    "Let's see the number of occurences per City. But it seems like there are so many values in the City variable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bfd14c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375\n"
     ]
    }
   ],
   "source": [
    "print(clean_coffee_df['City'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a95c0c3",
   "metadata": {},
   "source": [
    "We can't manually inspect the list this long! ‚ùå"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9742917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City\n",
       "Washington       26\n",
       "New York City    17\n",
       "Oklahoma City    15\n",
       "Houston          15\n",
       "Birmingham       13\n",
       "                 ..\n",
       "Silver Spring     1\n",
       "Conroe            1\n",
       "Bundoran          1\n",
       "Daytona Beach     1\n",
       "Wirral            1\n",
       "Name: count, Length: 375, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_coffee_df['City'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777979ae",
   "metadata": {},
   "source": [
    "Fuzzy matching can be used to find potential values that are represented differently. ‚úÖ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a2e0106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charleston ‚Üî Charlton: 88.88888888888889\n",
      "Charlton ‚Üî Carlton: 93.33333333333333\n",
      "Charlton ‚Üî Charleston: 88.88888888888889\n",
      "Carlton ‚Üî Charlton: 93.33333333333333\n",
      "Salinas ‚Üî Sallins: 85.71428571428572\n",
      "Sallins ‚Üî Salinas: 85.71428571428572\n"
     ]
    }
   ],
   "source": [
    "cities = clean_coffee_df['City'].unique()\n",
    "\n",
    "for city in cities:\n",
    "    matches = process.extract(city, cities, scorer = fuzz.ratio, limit = 5)\n",
    "    for match, score, _ in matches:\n",
    "        if city != match and score > 85:\n",
    "            print(f\"{city} ‚Üî {match}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253ef91f",
   "metadata": {},
   "source": [
    "The code only returned City values with names spelled closely, but there is no same value represented in multiple ways!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e0c193",
   "metadata": {},
   "source": [
    "Lastly, we check if the Loyalty Card Ownership variable has any other values than \"True\" or \"False\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d1e5dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False]\n"
     ]
    }
   ],
   "source": [
    "print(clean_coffee_df['Loyalty Card'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057b0cdd",
   "metadata": {},
   "source": [
    "In terms of multiple representations, our dataset has been cleaned! Wahoo! ‚ú®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e84d2f",
   "metadata": {},
   "source": [
    "### Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf4e4fa",
   "metadata": {},
   "source": [
    "Some variables may have unfilled values. The lack of values may make some algorithms and functions produce errors, sway bias, or make for inaccurate conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17fa4d5",
   "metadata": {},
   "source": [
    "We can't allow that to happen! Let's fill in the gaps! üï≥Ô∏èüßë‚Äçü¶Ø"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312cdb34",
   "metadata": {},
   "source": [
    "Have this code snippet to check which variables have null values in their observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b089a1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email           206\n",
      "Phone Number    135\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Showing the number of missing values per column\n",
    "missing_data = clean_coffee_df.isnull().sum()\n",
    "\n",
    "# Displaying only columns with missing data\n",
    "print(missing_data[missing_data > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051d46e0",
   "metadata": {},
   "source": [
    "The only variables with null values are the Phone Number and Email of the customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcc0f3f",
   "metadata": {},
   "source": [
    "There are three approaches we can go with regarding these values\n",
    "1. Dropping the columns. If they aren't be essential.\n",
    "2. Leaving them as is. If they won't be used.\n",
    "3. Replacing with \"Unknown\" or other null-indicating strings. If they might be used or might be filled up for later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc2dcec",
   "metadata": {},
   "source": [
    "As a bit of a spoiler, this notebook will focus primarily on marketing and identifying trends. \n",
    "\n",
    "Let's just say the company which needs the data analyses uses the Email and Phone Numbers to send newsletters and text notifications for upcoming deals and product promotions. üìàüìâ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafdc956",
   "metadata": {},
   "source": [
    "This means we will need the contacts of the customers in the future, meaning we'll go with option 3 and replace the null values with \"NaN\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "340d9c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing empty strings with NaN first\n",
    "clean_coffee_df['Phone Number'] = clean_coffee_df['Phone Number'].replace(r'^\\s*$', np.nan, regex=True)\n",
    "clean_coffee_df['Email'] = clean_coffee_df['Email'].replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "# Replacing NaN values with unknown\n",
    "clean_coffee_df[['Phone Number', 'Email']] = clean_coffee_df[['Phone Number', 'Email']].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2264436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Showing the number of missing values per column\n",
    "missing_data = clean_coffee_df.isnull().sum()\n",
    "\n",
    "# Displaying only columns with missing data\n",
    "print(missing_data[missing_data > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20380ac8",
   "metadata": {},
   "source": [
    "That's all for the missing data! I hope we didn't miss anything. üòÜ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee77ca7",
   "metadata": {},
   "source": [
    "### Duplicate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef4ae18",
   "metadata": {},
   "source": [
    "Sometimes, data can be recorded multiple times but have almost the exact same values.\n",
    "\n",
    "We have to look out for these since, again, they might skew our analysis and make it inaccurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8fab10",
   "metadata": {},
   "source": [
    "Use the following code snippet to check whether there are duplicate observations for the Product and Order ID since these should not repeat. ‚úåÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59c37ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print((clean_coffee_df.duplicated(subset=['Order ID', 'Product ID'])).sum())\n",
    "print((clean_coffee_df.duplicated(subset=['Customer Name', 'Product ID'])).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c032239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Email</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Address Line 1</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Loyalty Card</th>\n",
       "      <th>Coffee Type</th>\n",
       "      <th>Roast Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>Unit Price</th>\n",
       "      <th>Price per 100g</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NOP-21394-646</td>\n",
       "      <td>2021-05-23</td>\n",
       "      <td>16982-35708-BZ</td>\n",
       "      <td>L-D-2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>Nealson Cuttler</td>\n",
       "      <td>ncuttler5g@parallels.com</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1 Melvin Circle</td>\n",
       "      <td>Washington</td>\n",
       "      <td>United States</td>\n",
       "      <td>20535</td>\n",
       "      <td>False</td>\n",
       "      <td>Lib</td>\n",
       "      <td>D</td>\n",
       "      <td>2.5</td>\n",
       "      <td>29.785</td>\n",
       "      <td>1.1914</td>\n",
       "      <td>3.87205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NOP-21394-646</td>\n",
       "      <td>2021-05-23</td>\n",
       "      <td>16982-35708-BZ</td>\n",
       "      <td>L-D-2.5</td>\n",
       "      <td>3</td>\n",
       "      <td>Nealson Cuttler</td>\n",
       "      <td>ncuttler5g@parallels.com</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1 Melvin Circle</td>\n",
       "      <td>Washington</td>\n",
       "      <td>United States</td>\n",
       "      <td>20535</td>\n",
       "      <td>False</td>\n",
       "      <td>Lib</td>\n",
       "      <td>D</td>\n",
       "      <td>2.5</td>\n",
       "      <td>29.785</td>\n",
       "      <td>1.1914</td>\n",
       "      <td>3.87205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Order ID Order Date     Customer ID Product ID  Quantity  \\\n",
       "197  NOP-21394-646 2021-05-23  16982-35708-BZ    L-D-2.5         2   \n",
       "198  NOP-21394-646 2021-05-23  16982-35708-BZ    L-D-2.5         3   \n",
       "\n",
       "       Customer Name                     Email Phone Number   Address Line 1  \\\n",
       "197  Nealson Cuttler  ncuttler5g@parallels.com      Unknown  1 Melvin Circle   \n",
       "198  Nealson Cuttler  ncuttler5g@parallels.com      Unknown  1 Melvin Circle   \n",
       "\n",
       "           City        Country Postcode  Loyalty Card Coffee Type Roast Type  \\\n",
       "197  Washington  United States    20535         False         Lib          D   \n",
       "198  Washington  United States    20535         False         Lib          D   \n",
       "\n",
       "     Size  Unit Price  Price per 100g   Profit  \n",
       "197   2.5      29.785          1.1914  3.87205  \n",
       "198   2.5      29.785          1.1914  3.87205  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_coffee_df.duplicated(subset=['Order ID', 'Product ID']).sum()\n",
    "clean_coffee_df[clean_coffee_df.duplicated(subset=['Order ID', 'Product ID'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f27bcd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Email</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Address Line 1</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Loyalty Card</th>\n",
       "      <th>Coffee Type</th>\n",
       "      <th>Roast Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>Unit Price</th>\n",
       "      <th>Price per 100g</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NOP-21394-646</td>\n",
       "      <td>2021-05-23</td>\n",
       "      <td>16982-35708-BZ</td>\n",
       "      <td>L-D-2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>Nealson Cuttler</td>\n",
       "      <td>ncuttler5g@parallels.com</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1 Melvin Circle</td>\n",
       "      <td>Washington</td>\n",
       "      <td>United States</td>\n",
       "      <td>20535</td>\n",
       "      <td>False</td>\n",
       "      <td>Lib</td>\n",
       "      <td>D</td>\n",
       "      <td>2.5</td>\n",
       "      <td>29.785</td>\n",
       "      <td>1.1914</td>\n",
       "      <td>3.87205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NOP-21394-646</td>\n",
       "      <td>2021-05-23</td>\n",
       "      <td>16982-35708-BZ</td>\n",
       "      <td>L-D-2.5</td>\n",
       "      <td>3</td>\n",
       "      <td>Nealson Cuttler</td>\n",
       "      <td>ncuttler5g@parallels.com</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1 Melvin Circle</td>\n",
       "      <td>Washington</td>\n",
       "      <td>United States</td>\n",
       "      <td>20535</td>\n",
       "      <td>False</td>\n",
       "      <td>Lib</td>\n",
       "      <td>D</td>\n",
       "      <td>2.5</td>\n",
       "      <td>29.785</td>\n",
       "      <td>1.1914</td>\n",
       "      <td>3.87205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>PJS-30996-485</td>\n",
       "      <td>2022-01-21</td>\n",
       "      <td>86579-92122-OC</td>\n",
       "      <td>A-L-0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>Brenn Dundredge</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>+1 (405) 369-5173</td>\n",
       "      <td>5 Morrow Street</td>\n",
       "      <td>Oklahoma City</td>\n",
       "      <td>United States</td>\n",
       "      <td>73129</td>\n",
       "      <td>True</td>\n",
       "      <td>Ara</td>\n",
       "      <td>L</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.885</td>\n",
       "      <td>1.9425</td>\n",
       "      <td>0.34965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>NCH-55389-562</td>\n",
       "      <td>2019-04-27</td>\n",
       "      <td>86579-92122-OC</td>\n",
       "      <td>A-L-0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>Brenn Dundredge</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>+1 (405) 369-5173</td>\n",
       "      <td>5 Morrow Street</td>\n",
       "      <td>Oklahoma City</td>\n",
       "      <td>United States</td>\n",
       "      <td>73129</td>\n",
       "      <td>True</td>\n",
       "      <td>Ara</td>\n",
       "      <td>L</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.885</td>\n",
       "      <td>1.9425</td>\n",
       "      <td>0.34965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Order ID Order Date     Customer ID Product ID  Quantity  \\\n",
       "197  NOP-21394-646 2021-05-23  16982-35708-BZ    L-D-2.5         2   \n",
       "198  NOP-21394-646 2021-05-23  16982-35708-BZ    L-D-2.5         3   \n",
       "953  PJS-30996-485 2022-01-21  86579-92122-OC    A-L-0.2         1   \n",
       "958  NCH-55389-562 2019-04-27  86579-92122-OC    A-L-0.2         2   \n",
       "\n",
       "       Customer Name                     Email       Phone Number  \\\n",
       "197  Nealson Cuttler  ncuttler5g@parallels.com            Unknown   \n",
       "198  Nealson Cuttler  ncuttler5g@parallels.com            Unknown   \n",
       "953  Brenn Dundredge                   Unknown  +1 (405) 369-5173   \n",
       "958  Brenn Dundredge                   Unknown  +1 (405) 369-5173   \n",
       "\n",
       "      Address Line 1           City        Country Postcode  Loyalty Card  \\\n",
       "197  1 Melvin Circle     Washington  United States    20535         False   \n",
       "198  1 Melvin Circle     Washington  United States    20535         False   \n",
       "953  5 Morrow Street  Oklahoma City  United States    73129          True   \n",
       "958  5 Morrow Street  Oklahoma City  United States    73129          True   \n",
       "\n",
       "    Coffee Type Roast Type  Size  Unit Price  Price per 100g   Profit  \n",
       "197         Lib          D   2.5      29.785          1.1914  3.87205  \n",
       "198         Lib          D   2.5      29.785          1.1914  3.87205  \n",
       "953         Ara          L   0.2       3.885          1.9425  0.34965  \n",
       "958         Ara          L   0.2       3.885          1.9425  0.34965  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_coffee_df.duplicated(subset=['Customer Name', 'Product ID']).sum()\n",
    "clean_coffee_df[clean_coffee_df.duplicated(subset=['Customer Name', 'Product ID'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a60e65e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Customer Name                     Email\n",
      "0       Aloisia Allner         aallner0@lulu.com\n",
      "1       Aloisia Allner         aallner0@lulu.com\n",
      "268   Anselma Attwater     aattwater5u@wikia.com\n",
      "210   Anselma Attwater     aattwater5u@wikia.com\n",
      "469        Ailey Brash      abrashda@plala.or.jp\n",
      "..                 ...                       ...\n",
      "579      Tymon Zanetti   tzanettig2@gravatar.com\n",
      "547  Wilek Lightollers  wlightollersf9@baidu.com\n",
      "549  Wilek Lightollers  wlightollersf9@baidu.com\n",
      "256    Zacharias Kiffe  zkiffe74@cyberchimps.com\n",
      "249    Zacharias Kiffe  zkiffe74@cyberchimps.com\n",
      "\n",
      "[113 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Count duplicate emails (excluding missing)\n",
    "duplicate_emails = clean_coffee_df[clean_coffee_df.duplicated(subset=['Email'], keep=False) & (clean_coffee_df['Email'] != \"Unknown\")]\n",
    "\n",
    "print(duplicate_emails[['Customer Name', 'Email']].sort_values('Email'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdb67f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fuzzywuzzy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfuzzywuzzy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fuzz, process\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Get unique customer names\u001b[39;00m\n\u001b[32m      4\u001b[39m customer_names = clean_coffee_df[\u001b[33m'\u001b[39m\u001b[33mCustomer Name\u001b[39m\u001b[33m'\u001b[39m].dropna().unique()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'fuzzywuzzy'"
     ]
    }
   ],
   "source": [
    "# Get unique customer names\n",
    "customer_names = clean_coffee_df['Customer Name'].dropna().unique()\n",
    "\n",
    "# Find close matches using fuzzy matching\n",
    "for name in customer_names:\n",
    "    matches = process.extract(name, customer_names, scorer=fuzz.ratio, limit=5)\n",
    "    for match, score, _ in matches:\n",
    "        if name != match and score >= 85:  # Similar names above 85%\n",
    "            print(f\"{name} ‚Üî {match}: {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aa3e30",
   "metadata": {},
   "source": [
    "Looks like we have a customer with two different orders under the same Order ID...\n",
    "\n",
    "No worries!. We can aggregate their order into just one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efb8aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_coffee_df = clean_coffee_df.groupby(['Order ID', 'Product ID'], as_index=False).agg({\n",
    "    'Quantity': 'sum',\n",
    "    'Profit': 'sum',\n",
    "    'Customer ID': 'first',\n",
    "    'Customer Name': 'first',\n",
    "    'Email': 'first',\n",
    "    'Phone Number': 'first',\n",
    "    'Address Line 1': 'first',\n",
    "    'City': 'first',\n",
    "    'Country': 'first',\n",
    "    'Postcode': 'first',\n",
    "    'Loyalty Card': 'first',\n",
    "    'Coffee Type': 'first',\n",
    "    'Roast Type': 'first',\n",
    "    'Size': 'first',\n",
    "    'Unit Price': 'first',\n",
    "    'Price per 100g': 'first',\n",
    "    'Order Date': 'first'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414cb034",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = clean_coffee_df.duplicated(subset=['Order ID', 'Product ID'], keep=False)\n",
    "clean_coffee_df[duplicates].sort_values(by=['Order ID', 'Product ID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae59b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_coffee_df.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350e6aa6",
   "metadata": {},
   "source": [
    "### Inconsistent Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2119669f",
   "metadata": {},
   "source": [
    "Sometimes, values entered manually can be formatted differently. We need to make sure that strings and categorical data have the same cases, spelling, formats, and no extra spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0887ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leading/trailing spaces from all string columns\n",
    "for col in clean_coffee_df.select_dtypes(include='object').columns:\n",
    "    clean_coffee_df[col] = clean_coffee_df[col].str.strip()\n",
    "\n",
    "# Standardize Customer Name to Title Case (e.g., \"John Doe\")\n",
    "clean_coffee_df['Customer Name'] = clean_coffee_df['Customer Name'].str.title()\n",
    "\n",
    "# Lowercase City and Country for consistency\n",
    "clean_coffee_df['City'] = clean_coffee_df['City'].str.title()\n",
    "clean_coffee_df['Country'] = clean_coffee_df['Country'].str.title()\n",
    "\n",
    "# Remove internal spaces in Postcodes (e.g., \"12 345\" -> \"12345\")\n",
    "clean_coffee_df['Postcode'] = clean_coffee_df['Postcode'].str.replace(r'\\s+', '', regex=True)\n",
    "\n",
    "# Standardize Emails to lowercase\n",
    "clean_coffee_df['Email'] = clean_coffee_df['Email'].str.title()\n",
    "\n",
    "# Lowercase for Coffee Type and Roast Type to standardize categories\n",
    "clean_coffee_df['Coffee Type'] = clean_coffee_df['Coffee Type'].str.title()\n",
    "clean_coffee_df['Roast Type'] = clean_coffee_df['Roast Type'].str.title()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3680259",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_coffee_df['City'].unique())\n",
    "print(clean_coffee_df['Coffee Type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ff76f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_coffee_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0790340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if phone number has 10 or 11 digits\n",
    "check_phone_format = clean_coffee_df['Phone Number'].apply(lambda x: len(x) in [10, 11])\n",
    "print(check_phone_format.value_counts())  # True/False counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b63a340",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db4efee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e3131fc",
   "metadata": {},
   "source": [
    "### Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42d3a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98bee757",
   "metadata": {},
   "source": [
    "Always remember that data cleaning depends specifically on the context and use of the dataset. It can heavily affect and sway the results of analysis, so we must do it carefully. üìå"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b4b17e",
   "metadata": {},
   "source": [
    "Our dataset is now squeaky clean! We can now proceed with analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7da8d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_coffee_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2439fc6",
   "metadata": {},
   "source": [
    "# Target Research Question üî¨‚ú®\n",
    "\n",
    "#### _`\"How can we optimize business strategies by understanding the factors that affect sales?\"`_\n",
    "\n",
    "In order to provide scope, purpose, and clarity, the above question will serve as the main foundation of data analysis upon the Coffee Bean Sale Dataset. It will guide in identifying patterns, relationships, and key insights that can inform business decision-making to hopefully draw insights on the coffee bean industry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fba408",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis üîç‚ú®\n",
    "\n",
    "Now that the dataset has been cleaned, we can start exploring it to better understand its structure, contents, and patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d42d84",
   "metadata": {},
   "source": [
    "People tend to prefer certain flavors of coffee depending on the season like how Pumpkin Spice Lattes take over Autumn. By knowing which coffee beans and roasts are most profitable, we can make smarter decisions about stocks and promotions. This begs the question...\n",
    "\n",
    "### _`\"Which coffee bean and roast type is the most profitable per season?\"`_ ‚õÖüìà‚ú®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beee6c2",
   "metadata": {},
   "source": [
    "To answer this question, the variables of interest are:\n",
    "- **`Order Date`**: the date a order was placed\n",
    "- **`Coffee Type`**: the blend or type of coffee (e.g., Arabica, Robusta, Liberica, Excelsa)\n",
    "- **`Roast Type`**: the level of roast (e.g., light, medium, dark)\n",
    "- **`Profit`**: the amount of profit from a sale\n",
    "- **`Quantity`**: the number of units ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6b098f",
   "metadata": {},
   "source": [
    "#### **Seasons**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd04fcf6",
   "metadata": {},
   "source": [
    "Since the customers from the dataset are mostly from the the United States of America, we will be using the seasons from that country. The seasons are specifically **winter**, **spring**, **summer** and **fall** and they will be derived from the `Order Date`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdca73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the seasons based on the month\n",
    "def get_season(date) :\n",
    "    month = date.month\n",
    "    if month in [3, 4, 5] : return 'Spring'\n",
    "    elif month in [6, 7, 8] : return 'Summer'\n",
    "    elif month in [9, 10, 11] : return 'Fall'\n",
    "    else: return 'Winter'\n",
    "\n",
    "clean_coffee_df['Season'] = clean_coffee_df['Order Date'].apply(get_season)\n",
    "clean_coffee_df[['Order Date', 'Season']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b58fde4",
   "metadata": {},
   "source": [
    "#### **Total Quantity Sold For Each Coffee Type per Season**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3833a41",
   "metadata": {},
   "source": [
    "In order to understand the seasonal demands per coffee type (e.g., Arabica, Robusta), we will compute the total quantity sold for each coffee type per season. This will help us identify the coffee type that is most preferred during each season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929c2b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by season and coffee type and summing up the quantity\n",
    "coffee_total_quantity = clean_coffee_df.groupby(['Season', 'Coffee Type'])['Quantity'].sum().reset_index()\n",
    "\n",
    "# Sorting the seasons in ascending order and quantity in descending order\n",
    "coffee_total_quantity = coffee_total_quantity.sort_values(['Season', 'Quantity'], ascending=[True, False])\n",
    "\n",
    "print(\"Total Quantity Sold For Each Coffee Type per Season:\\n\")\n",
    "print(coffee_total_quantity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff2fb81",
   "metadata": {},
   "source": [
    "During the **Fall** and **Summer**, the most sold coffee type for both seasons is **Arabica**, with a quantity of **233** and **247** units sold, respectively. During the **Spring**, the most sold coffee type is **Robusta**, with a quantity of **254** units sold. Lastly, during the **Winter**, the most sold coffee type is **Liberica**, with a quantity of **247** units sold. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8305e6",
   "metadata": {},
   "source": [
    "#### **Total Quantity Sold For Each Roast Type per Season**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8233035",
   "metadata": {},
   "source": [
    "In order to understand the seasonal demands per roast type (e.g., light, medium, dark), we will compute the total quantity sold for each roast type per season. This will help us identify the roast type that is most preferred during each season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da863c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by season and roast type and summing up the quantity\n",
    "roast_total_quantity = clean_coffee_df.groupby(['Season', 'Roast Type'])['Quantity'].sum().reset_index()\n",
    "\n",
    "# Sorting the seasons in ascending order and quantity in descending order\n",
    "roast_total_quantity = roast_total_quantity.sort_values(['Season', 'Quantity'], ascending=[True, False])\n",
    "\n",
    "print(\"Total Quantity Sold For Each Roast Type per Season:\\n\")\n",
    "print(roast_total_quantity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fff5c01",
   "metadata": {},
   "source": [
    "During the **Winter** and **Summer**, the most sold roast type for both seasons is **dark**, with a quantity of **316** and **311** units sold, respectively. During the **Fall**, the most sold roast type is **medium**, with a quantity of **309** units sold. Lastly, during the **Spring**, the most sold roast type is **light**, with a quantity of **364** units sold. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92255def",
   "metadata": {},
   "source": [
    "#### **Top Quantity Sold For Each Coffee and Roast Type Combination per Season**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2394b3",
   "metadata": {},
   "source": [
    "In order to be a step closer to identifying what coffee and roast type is the most profitable per season, we will compute for the most quantity sold coffee and roast type combination per season. This will help us compare which coffee and roast type combination is the most sold and the most profitable during each season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dfe93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by season, coffee type, and roast type and summing up the quantity\n",
    "combination_quantity = clean_coffee_df.groupby(['Season', 'Coffee Type', 'Roast Type'])['Quantity'].sum().reset_index()\n",
    "\n",
    "# Sorting and retrieving the top selling combination per season\n",
    "top_combination_quantity = combination_quantity.sort_values(['Season', 'Quantity'], ascending=[True, False]) \\\n",
    "                                   .groupby('Season').first().reset_index()\n",
    "\n",
    "print(\"Top Quantity Sold for Each Coffee and Roast Type per Season:\\n\")\n",
    "print(top_combination_quantity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1270e7",
   "metadata": {},
   "source": [
    "During both the **Fall** and **Winter**, the most sold combination is **Arabica Medium Roast**, both having a quantity of **98** units sold. During the **Spring**, the most sold combination is **Excelsa Light Roast**, with a quantity of **106** units sold. During the **Summer**, the most sold combination is **Robusta Dark Roast**, with a quantity of **110** units sold.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757aca8c",
   "metadata": {},
   "source": [
    "#### **Most Profitable Coffee and Roast Type per Season**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912e1657",
   "metadata": {},
   "source": [
    "In order to answer our main EDA question of determining which coffee bean and roast type is the most profitable per season is, we will get the total profit of each season, coffee and roast type group and retreieve the combinations with the highest total profit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592de241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the total profit by multiplying quantity and profit\n",
    "clean_coffee_df['Total Profit'] = clean_coffee_df['Quantity'] * clean_coffee_df['Profit']\n",
    "\n",
    "# Grouping by season, coffee type, and roast type and then summing up the total profit for each group\n",
    "combination_season_profit = clean_coffee_df.groupby(['Season', 'Coffee Type', 'Roast Type'])['Total Profit'].sum().reset_index()\n",
    "\n",
    "# the coffee and roast type combination with the highest total profit appears first\n",
    "top_combination_per_season = combination_season_profit.sort_values(['Season', 'Total Profit'], ascending=[True, False]).groupby('Season').first().reset_index()\n",
    "\n",
    "print(top_combination_per_season)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfbc1ee",
   "metadata": {},
   "source": [
    "The most profitable coffee and roast type combination during the **Fall** is **Liberica Dark Roast** in contrast to **Arabica Medium Roast** having the most quantity sold. The most profitable combination during **Spring** is **Liberica Light Roast** in contrast to **Excelsa Light Roast** having the most quantity sold. The most profitable combination during **Summer** is **Excelsa Medium Roast** in contrast to **Robusta Dark Roast** having the most quantity sold. Lastly, the most profitable combination during **Winter** is **Liberica Dark Roast** in contrast to **Arabica Medium Roast** having the most quantity sold.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0c605a",
   "metadata": {},
   "source": [
    "#### **Which season has the highest overall coffee sales profit?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31e7c2b",
   "metadata": {},
   "source": [
    "Identifying the season with the highest overall coffee sales profit will help us understand which season generates the most coffee sales. By analyzing seasonal trends, businesses can better anticipate coffee demand and maximize profitability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deac87e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by season and summing up total profit\n",
    "season_profit = clean_coffee_df.groupby('Season')['Total Profit'].sum()\n",
    "\n",
    "# Sorting the profit per season in descending order\n",
    "season_profit_sorted = season_profit.sort_values(ascending=False)\n",
    "\n",
    "print(\"Total Profit per Season:\")\n",
    "for season, profit in season_profit_sorted.items():\n",
    "    print(f\"{season}: ${'{:.2f}'.format(profit)}\")\n",
    "\n",
    "top_season = season_profit_sorted.idxmax()\n",
    "\n",
    "print(f\"\\nSeason with the highest profit: {top_season}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fea01e",
   "metadata": {},
   "source": [
    "The season that gives the highest overall coffee sales profit is **Spring** with a total profit of **$1,252.69**. The season with the least overall coffee sales profit is **Summer**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1dac29",
   "metadata": {},
   "source": [
    "#### **Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f9f25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by season, coffee and roast type to get total profit\n",
    "profit_per_combo = clean_coffee_df.groupby(['Season', 'Coffee Type', 'Roast Type'])['Total Profit'].sum().reset_index()\n",
    "\n",
    "# Creating a column for combining coffee and roast type\n",
    "profit_per_combo['CoffeeRoast'] = profit_per_combo['Coffee Type'].astype(str) + ' - ' + profit_per_combo['Roast Type'].astype(str)\n",
    "\n",
    "pivot_df = profit_per_combo.pivot(index='Season', columns='CoffeeRoast', values='Total Profit')\n",
    "\n",
    "pivot_df.plot(kind='line', marker='o', figsize=(12, 6))\n",
    "plt.title(\"Seasonal Profit by Coffee and Roast Type\")\n",
    "plt.xlabel(\"Season\")\n",
    "plt.ylabel(\"Total Profit ($)\")\n",
    "plt.grid(True)\n",
    "plt.legend(title=\"Coffee - Roast Type\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7e3b0e",
   "metadata": {},
   "source": [
    "**Figure 1. Line Chart of Seasonal Profits by Coffee and Roast Type**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae3cc6f",
   "metadata": {},
   "source": [
    "The line chart shows the total profit made by each coffee and roast type combination on the y-axis. The four seasons are shown on the y-axis and a legend for each combination is shown on the upper right part of the figure.\n",
    "\n",
    "The figure reflects the profitability of each coffee and roast type per season and as seen, **Spring** is the season  that gives the combination (**Liberica Light Roast**) with the highest total profit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e6d572",
   "metadata": {},
   "source": [
    "### _`\"How does loyalty card ownership influence customer purchasing behavior?\"`_ üßëüí≥‚ú®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9e2259",
   "metadata": {},
   "source": [
    "This analysis explores whether loyalty card ownership has an influence on customer purchasing behavior.  Specifically, we investigate whether there is a statistically significant difference in the number of coffee bean units ordered by customers who have a loyalty card compared to those who do not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b6a394",
   "metadata": {},
   "source": [
    "To do this, we focus on two variables:\n",
    "\n",
    "- **`Loyalty Card`**: From the `customers` dataset, indicating whether a customer has a loyalty card (True or False).\n",
    "- **`Quantity`**: From the `orders` dataset, representing how many units of coffee beans were ordered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b30c7f",
   "metadata": {},
   "source": [
    "#### **Group by Ownership**\n",
    "\n",
    "We then divide the dataset into two groups based on loyalty card status:\n",
    "- `owners`: Customers who have a loyalty card (Loyalty Card == True)\n",
    "- `non_owners`: Customers who do not have a loyalty card (Loyalty Card == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe4b07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "owners = clean_coffee_df[clean_coffee_df['Loyalty Card'] == True]['Quantity']\n",
    "non_owners = clean_coffee_df[clean_coffee_df['Loyalty Card'] == False]['Quantity']\n",
    "\n",
    "ownership_table = pd.DataFrame({\n",
    "    'Loyalty Card Owners': owners.reset_index(drop = True),\n",
    "    'Non-Owners': non_owners.reset_index(drop = True)\n",
    "})\n",
    "\n",
    "ownership_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c665d4",
   "metadata": {},
   "source": [
    "To assess the relationship, we use an **Independent Samples T-test**, which allows us to compare the means of two groups and determine whether any observed difference is statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815f09ca",
   "metadata": {},
   "source": [
    "Before conducting the test, we define our hypotheses:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cb4f68",
   "metadata": {},
   "source": [
    "#### **Hypothesis Testing (T-test)**\n",
    "**Null Hypothesis (H‚ÇÄ)**: Loyalty card ownership does not influence purchasing behavior.\n",
    "\n",
    "**Alternative Hypothesis (H‚Çê)**: Loyalty card ownership does influence purchasing behavior.\n",
    "\n",
    "We will use an independent samples T-test to determine if the difference in purchasing behavior between loyalty card owners and non-owners is statistically significant based on the T-statistic and p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5f638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stat, p_value = ttest_ind(owners, non_owners, equal_var=False)\n",
    "\n",
    "print(f\"Owners Mean Quantity (True): {owners.mean():.2f}\")\n",
    "print(f\"Non-Owners Mean Quantity (False): {non_owners.mean():.2f}\")\n",
    "print(f\"T-statistic: {t_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5049887",
   "metadata": {},
   "source": [
    "The average quantity ordered by **loyalty card owners** is **3.48**, while **non-owners** order an average of **3.62**.\n",
    "\n",
    "The **T-statistic** is **-1.3518**, and the **p-value** is **0.1768**, which is greater than **0.05**. This means the result is **not statistically significant**. \n",
    "\n",
    "Therefore, we **fail to reject the null hypothesis**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52cf362",
   "metadata": {},
   "source": [
    "#### **Dot Plot**\n",
    "\n",
    "The dot plot below further illustrates this relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227472b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 6))\n",
    "sns.stripplot(\n",
    "    data = clean_coffee_df,\n",
    "    x = 'Loyalty Card',\n",
    "    y = 'Quantity',\n",
    "    hue = 'Loyalty Card',       \n",
    "    legend = False,             \n",
    "    jitter = 0.3,\n",
    "    size = 6,\n",
    "    marker = 'o',\n",
    "    edgecolor = 'auto',\n",
    "    linewidth = 0.5,\n",
    "    palette = 'Set2'\n",
    ")\n",
    "\n",
    "plt.title('Quantity Ordered by Loyalty Card Ownership')\n",
    "plt.xlabel('Loyalty Card')\n",
    "plt.ylabel('Quantity Ordered')\n",
    "plt.grid(True, axis = 'y', linestyle = '--', alpha = 0.4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f6e891",
   "metadata": {},
   "source": [
    "**Figure 2. Dot Plot of Quantity of Orders based on Loyalty Card Ownership**\n",
    "\n",
    "The dot plot shows the distribution of coffee bean quantities ordered by customers, grouped by loyalty card ownership. Each dot represents a single transaction, with the quantity ordered on the y-axis and the loyalty card status on the x-axis.\n",
    "\n",
    "As seen in the figure, loyalty card owners and non-owners display similar ordering patterns. This diagram aligns with the t-test results, which show no significant difference in mean quantity ordered between the groups (t = -1.3518, p = 0.1768)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d6d855",
   "metadata": {},
   "source": [
    "üìå **Conclusion**: There is no statistically significant evidence that loyalty card ownership influences the quantity of coffee beans ordered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dd44d7",
   "metadata": {},
   "source": [
    "While our initial analysis suggests that loyalty card ownership does not significantly affect overall purchasing behavior,  it does not directly answer whether those with loyalty cards tend to order larger quantities of coffee beans. A customer may still purchase larger quantites in order.\n",
    "\n",
    "To further investigate this, we now ask:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87971261",
   "metadata": {},
   "source": [
    "**Do loyalty card owners order in larger quantities of coffee beans compared to non-owners?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c4ada5",
   "metadata": {},
   "source": [
    "To answer this question, we use the same variables from the previous analysis:\n",
    "- **`Loyalty Card`**: From the `customers` dataset, indicating whether a customer has a loyalty card (True or False).\n",
    "- **`Quantity`**: From the `orders` dataset, representing how many units of coffee beans were ordered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24ebd19",
   "metadata": {},
   "source": [
    "We will also use the same groupings from the initial analysis:\n",
    "- `owners`: Customers who have a loyalty card (Loyalty Card == True)\n",
    "- `non_owners`: Customers who do not have a loyalty card (Loyalty Card == False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654a490a",
   "metadata": {},
   "source": [
    "To investigate this, we will conduct a **One-tailed Independent Samples T-test** to determine if loyalty card owners purchase in larger amounts compared to non-owners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c582ee84",
   "metadata": {},
   "source": [
    "Before conducting the test, we define our hypotheses:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d97bba6",
   "metadata": {},
   "source": [
    "**Null Hypothesis (H‚ÇÄ)**: Loyalty card owners do not order in larger quantities than non-owners (Œº‚ÇÅ ‚â§ Œº‚ÇÇ).\n",
    "\n",
    "**Alternative Hypothesis (H‚Çê)**: Loyalty card owners order in larger quantities than non-owners (Œº‚ÇÅ > Œº‚ÇÇ).\n",
    "\n",
    "We will use a One-tailed Independent Samples T-test to determine if loyalty card owners order significantly more coffee beans than non-owners, based on the T-statistic and p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713ffdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stat, p_value_two_tailed = ttest_ind(owners, non_owners, equal_var=False)\n",
    "p_value_one_tailed = p_value_two_tailed / 2\n",
    "\n",
    "print(f\"Owners Mean Quantity (True): {owners.mean():.2f}\")\n",
    "print(f\"Non-Owners Mean Quantity (False): {non_owners.mean():.2f}\")\n",
    "print(f\"T-statistic: {t_stat:.4f}\")\n",
    "print(f\"One-tailed P-value: {p_value_one_tailed:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361e23f6",
   "metadata": {},
   "source": [
    "Thhe **One-tailed p-value** is **0.0884**, which is greater than **0.05**. This means the result is **not statistically significant**. \n",
    "\n",
    "Therefore, we **fail to reject the null hypothesis**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbc4ae2",
   "metadata": {},
   "source": [
    "This relationship is also shown in the bar plot below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e37a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 6))\n",
    "sns.barplot(\n",
    "    data = clean_coffee_df,\n",
    "    x = 'Loyalty Card',\n",
    "    y = 'Quantity',\n",
    "    hue = 'Loyalty Card',   \n",
    "    palette = 'Set2',\n",
    "    legend = False          \n",
    ")\n",
    "plt.title(\"Average Quantity Ordered by Loyalty Card Ownership\")\n",
    "plt.xlabel(\"Loyalty Card\")\n",
    "plt.ylabel(\"Mean Quantity Ordered\")\n",
    "plt.grid(True, axis = 'y', linestyle = '--', alpha = 0.4)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d659a1",
   "metadata": {},
   "source": [
    "**Figure 3. Bar Chart of Average Quantities Ordered based on Loyalty Card Ownership**\n",
    "\n",
    "The bar plot displays the average quantity of coffee beans ordered by customers, grouped by loyalty card ownership. Each bar represents the mean quantity ordered for each group.\n",
    "\n",
    "As shown above, loyalty card owners do not appear to order larger quantities than non-owners. It supports the one-tailed t-test result, which found no significant evidence to support the claim that loyalty card owners order in greater quantities (t = -1.3518, one-tailed p = 0.0884)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f8b444",
   "metadata": {},
   "source": [
    "üìå **Conclusion**: There is insufficient evidence to conclude that loyalty card owners order in larger quantities of coffee beans compared to non-owners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648df10e",
   "metadata": {},
   "source": [
    "### _`\"Do the coffee products with higher unit prices generate more profit?\"`_ ‚òïüí∞‚ú®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f18ce8",
   "metadata": {},
   "source": [
    "In this analysis, we aim to determine whether there is a statistical relationship between the **unit price** of coffee products and their **total profit**. Specifically, we want to know if products with higher prices tend to generate more profit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1559daf",
   "metadata": {},
   "source": [
    "To answer this question, we focus on the following variables from the `products` dataset:\n",
    "\n",
    "- **`Unit Price`**: The retail price per unit of each coffee product.\n",
    "- **`Profit`**: The total profit associated with each product."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fc01ae",
   "metadata": {},
   "source": [
    "To assess this, we will use the **Pearson correlation coefficient**, which measures the strength and direction of a linear relationship between two continuous variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efe9c9f",
   "metadata": {},
   "source": [
    "Before conducting the test, we define our hypotheses:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceac123",
   "metadata": {},
   "source": [
    "**Null Hypothesis (H‚ÇÄ)**: There is no linear correlation between unit price and profit.  \n",
    "**Alternative Hypothesis (H‚Çê)**: There is a significant linear correlation between unit price and profit.\n",
    "\n",
    "We will calculate the Pearson correlation coefficient and interpret both the correlation value and the associated p-value to determine if the result is statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db216f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr, p_value = pearsonr(products['Unit Price'], products['Profit'])\n",
    "\n",
    "print(f\"Pearson correlation: {corr:.3f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bd8b64",
   "metadata": {},
   "source": [
    "The Pearson correlation coefficient between **Unit Price** and **Profit** is **0.939**, indicating a **very strong positive linear relationship**. \n",
    "\n",
    "Additionally, the **p-value is less than 0.05** (p = 0.0000), which means the result is **statistically significant**. Therefore, we **reject the null hypothesis**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e443c70a",
   "metadata": {},
   "source": [
    "The following scatterplot further illustrates this relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dccadad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.regplot(data=products, x='Unit Price', y='Profit', color='teal', line_kws={\"color\": \"red\"})\n",
    "\n",
    "plt.title('Scatterplot of Unit Price vs Profit')\n",
    "plt.xlabel('Unit Price')\n",
    "plt.ylabel('Profit')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd72863",
   "metadata": {},
   "source": [
    "**Figure 4. Scatterplot of Unit Price and Profit**  \n",
    "The scatterplot displays the relationship between **Unit Price** and **Profit** for each coffee product in the dataset. Each teal point represents a product, with its unit price on the x-axis and the corresponding profit on the y-axis.\n",
    "\n",
    "The red regression line illustrates the overall linear trend. As shown, products with higher unit prices tend to generate higher profits, confirming the positive relationship observed in the Pearson correlation analysis (r = 0.939, p < 0.001)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bdb975",
   "metadata": {},
   "source": [
    "üìå **Conclusion**: There exists a statistically significant linear correlation between unit price and profit among coffee products."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534c108b",
   "metadata": {},
   "source": [
    "While our initial analysis shows a strong positive correlation between unit price and profit, this does not account for how well each product actually sells. High-priced items may yield high per-unit profits, but low sales volumes could limit their total profitability. To explore this further, we now ask:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69059526",
   "metadata": {},
   "source": [
    "**Do sales volumes influence total profit for higher-priced coffee products?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f16e2bf",
   "metadata": {},
   "source": [
    "To answer this question, we focus on the following variables:\n",
    "\n",
    "- From the `products` dataset:\n",
    "  - **Unit Price**: The retail price per unit of each coffee product.\n",
    "  - **Profit**: The total profit associated with each product.\n",
    "- From the `orders` dataset:\n",
    "  - **Quantity**: The number of units ordered per product."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996af4a5",
   "metadata": {},
   "source": [
    "This analysis will help determine whether limited demand for expensive products affects their overall contribution to profit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0bc265",
   "metadata": {},
   "source": [
    "Before conducting the test, we define our hypotheses:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bf8271",
   "metadata": {},
   "source": [
    "**Null Hypothesis (H‚ÇÄ)**: There is no significant linear correlation between sales volume (Quantity) and total profit for higher-priced coffee products.  \n",
    "**Alternative Hypothesis (H‚Çê)**: There is a significant linear correlation between sales volume (Quantity) and total profit for higher-priced coffee products.\n",
    "\n",
    "We will calculate the Pearson correlation coefficient and evaluate the associated p-value. This will allow us to determine both the strength of the linear relationship and whether the result is statistically significant at the conventional 0.05 significance level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ee9974",
   "metadata": {},
   "source": [
    "We will use `clean_coffee_df`, a merged and cleaned dataset combining product and order details needed to compute total profit per product."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d144dc13",
   "metadata": {},
   "source": [
    "#### **Group by Product**\n",
    "\n",
    "We group the merged data by each product to calculate:\n",
    "- Total quantity sold\n",
    "- Per-unit profit and unit price (from `products`)\n",
    "- Total profit = Quantity √ó Profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c48f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = clean_coffee_df.groupby(['Product ID', 'Coffee Type', 'Roast Type']) \\\n",
    "    .agg({\n",
    "        'Quantity': 'sum',\n",
    "        'Profit': 'first',\n",
    "        'Unit Price': 'first'\n",
    "    }).reset_index()\n",
    "\n",
    "grouped['Total Profit'] = grouped['Quantity'] * grouped['Profit']\n",
    "grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5f98c9",
   "metadata": {},
   "source": [
    "#### **Focus on High-Priced Products**\n",
    "\n",
    "We define \"high-priced\" as products whose unit price falls in the top 25% of all products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac93ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_price = grouped['Unit Price'].quantile(0.75)\n",
    "high_priced = grouped[grouped['Unit Price'] >= q3_price]\n",
    "high_priced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005ffedd",
   "metadata": {},
   "source": [
    "#### **Correlation Analysis**\n",
    "\n",
    "We calculate the Pearson correlation coefficient to assess the linear relationship between **quantity sold** and **total profit** for high-priced products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f023ec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr, pval = pearsonr(high_priced['Quantity'], high_priced['Total Profit'])\n",
    "\n",
    "print(f\"Pearson correlation: {corr:.3f}\")\n",
    "print(f\"P-value: {pval:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe12d57",
   "metadata": {},
   "source": [
    "The Pearson correlation coefficient between **Quantity** and **Total Profit** for higher-priced products is **0.301**, indicating a **weak positive linear relationship**. \n",
    "\n",
    "However, the **p-value is greater than 0.05** (p = 0.3418), so the result is **not statistically significant**. Therefore, we **fail to reject the null hypothesis**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a2c941",
   "metadata": {},
   "source": [
    "#### **Visualization**\n",
    "\n",
    "To visually support the correlation result, we generate a scatterplot with a regression line showing how quantity sold relates to total profit for high-priced products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fc1ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.regplot(\n",
    "    data=high_priced,\n",
    "    x='Quantity',\n",
    "    y='Total Profit',\n",
    "    color='teal',\n",
    "    line_kws={\"color\": \"red\"}\n",
    ")\n",
    "\n",
    "plt.title('Quantity Sold vs Total Profit (High-Priced Products)')\n",
    "plt.xlabel('Total Quantity Sold')\n",
    "plt.ylabel('Total Profit')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2137d12d",
   "metadata": {},
   "source": [
    "**Figure 5. Scatterplot based on Quantity Sold and Total Profit**  \n",
    "The scatterplot illustrates the relationship between **quantity sold** and **total profit** for high-priced coffee products. Each teal point represents a product, where the x-axis shows the total number of units sold and the y-axis displays the corresponding total profit.\n",
    "\n",
    "The red regression line represents the overall linear trend based on Pearson correlation analysis. While there is a slight upward trend, the distribution of points appears scattered, and no strong linear relationship is visually evident.\n",
    "\n",
    "This aligns with the earlier statistical result (r = 0.301, p = 0.3418), suggesting that the correlation between sales volume and total profit among high-priced items is weak and not statistically significant. This indicates that simply pricing products higher does not guarantee greater overall profit if the products do not sell in large volumes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a9c419",
   "metadata": {},
   "source": [
    "üìå **Conclusion**: There is no statistically significant linear correlation between sales volume and total profit for high-priced coffee products."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6007c8",
   "metadata": {},
   "source": [
    "# Conclusion ‚úÖ\n",
    "\n",
    "// INSERT CONCLUSION HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
